{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = open(\"./log-edu.txt\", \"r\")\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "norm_list = []\n",
    "lr_list = []\n",
    "for i in log:\n",
    "    data = i.split(\"|\")\n",
    "    train_loss_list.append(data[1])\n",
    "    val_loss_list.append(data[2])\n",
    "    norm_list.append(data[3])\n",
    "    lr_list.append(data[4])\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "norm = []\n",
    "lr = []\n",
    "\n",
    "for i in train_loss_list:\n",
    "    x = i.split(\":\")[1]\n",
    "    x = x.replace(\" \", \"\")\n",
    "    train_loss.append(float(x))\n",
    "\n",
    "for i in val_loss_list:\n",
    "    x = i.split(\":\")[1]\n",
    "    x = x.replace(\" \", \"\")\n",
    "    val_loss.append(float(x))\n",
    "\n",
    "for i in norm_list:\n",
    "    x = i.split(\":\")[1]\n",
    "    x = x.replace(\" \", \"\")\n",
    "    norm.append(float(x))\n",
    "\n",
    "for i in lr_list:\n",
    "    x = i.split(\":\")[1]\n",
    "    x = x.replace(\" \", \"\")\n",
    "    lr.append(float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x3094a3690>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x30973aa10>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x177199950>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x386541950>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        self.n_embd = n_embed\n",
    "        self.n_head = n_head\n",
    "        super().__init__()\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(self.n_embd, 3 * self.n_embd)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(self.n_embd, self.n_embd)\n",
    "        self.c_proj.NANOGPT_SCALE_INIT = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        # nh is \"number of heads\", hs is \"head size\", and C (number of channels) = nh * hs\n",
    "        # e.g. in GPT-2 (124M), n_head=12, hs=64, so nh*hs=C=768 channels in the Transformer\n",
    "        qkv = self.c_attn(x)\n",
    "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True) # flash attention\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "        # output projection\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 4 *  embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * embed_dim, embed_dim), \n",
    "        )\n",
    "        self.scale_init = 1\n",
    "    def forward(self, x):\n",
    "        return self.MLP(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, dropout):\n",
    "        super(Block, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.LayerNorm1 = nn.LayerNorm(embed_dim) \n",
    "        self.MultiheadAttention = CausalSelfAttention(self.embed_dim, self.num_heads)\n",
    "        self.LayerNorm2 = nn.LayerNorm(embed_dim)\n",
    "        self.MLP = MLP(embed_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.MultiheadAttention(self.LayerNorm1(x))\n",
    "        x = x + self.MLP(self.LayerNorm2(x))\n",
    "        return x\n",
    "\n",
    "class Model1(nn.Module):\n",
    "    def __init__(self, block_size, vocab_size, embed_dim, num_heads, num_blocks, dropout):\n",
    "        super(Model1, self).__init__()\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim  \n",
    "        self.num_heads = num_heads\n",
    "        self.num_blocks = num_blocks\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embed_dim)\n",
    "        self.positional_embedding = nn.Embedding(self.block_size, self.embed_dim)\n",
    "\n",
    "        self.blocks = nn.ModuleList([Block(self.embed_dim, self.num_heads, self.dropout) for _ in range(self.num_blocks)])\n",
    "\n",
    "        self.LayerNorm3 = nn.LayerNorm(self.embed_dim)\n",
    "        self.lm_linear = nn.Linear(self.embed_dim, self.vocab_size)\n",
    "        \n",
    "        #weight sharing scheme\n",
    "        self.lm_linear.weight = self.embedding.weight\n",
    "\n",
    "        # Apply parameter initialization as per GPT2 model\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        std = 0.02\n",
    "        if hasattr(module, \"NANOGPT_SCALE_INIT\"):\n",
    "            std *= (2 * self.num_blocks) ** -0.5\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std)\n",
    "\n",
    "        for pn, p in self.named_parameters():\n",
    "            print(f\"{pn=}\")        \n",
    "            print(f\"{p=}\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T = x.shape\n",
    "        x = self.embedding(x)\n",
    "        x = x + self.positional_embedding(torch.arange(T, device=device))\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        output = self.LayerNorm3(x)\n",
    "        output = self.lm_linear(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7996,  0.4056, -0.3603,  ..., -0.1176, -0.0853, -1.2004],\n",
      "        [-2.3562,  1.3322,  0.4245,  ...,  1.1111,  0.1710,  0.0472],\n",
      "        [-0.0683,  0.4869, -0.6299,  ..., -1.1739, -1.4428,  0.5852],\n",
      "        ...,\n",
      "        [ 0.3913, -0.1033, -0.5159,  ..., -1.3066,  0.8295, -1.6806],\n",
      "        [-0.0889, -0.0455, -2.0056,  ...,  0.1859, -0.6180,  0.5646],\n",
      "        [-0.1941,  0.7559, -2.2823,  ..., -1.2946, -1.0974, -0.5883]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0197,  0.0064, -0.0084,  ...,  0.0270,  0.0091,  0.0200],\n",
      "        [ 0.0233, -0.0262,  0.0293,  ..., -0.0184, -0.0054,  0.0310],\n",
      "        [-0.0132,  0.0074,  0.0095,  ..., -0.0215, -0.0145,  0.0010],\n",
      "        ...,\n",
      "        [ 0.0109,  0.0291, -0.0104,  ..., -0.0149,  0.0128,  0.0018],\n",
      "        [-0.0056,  0.0151, -0.0300,  ...,  0.0138,  0.0254,  0.0203],\n",
      "        [ 0.0303,  0.0164, -0.0016,  ..., -0.0044, -0.0028, -0.0251]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0258,  0.0145,  0.0236,  ..., -0.0258, -0.0208,  0.0156],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0094, -0.0061, -0.0148,  ..., -0.0055,  0.0084, -0.0030],\n",
      "        [ 0.0266, -0.0187,  0.0094,  ..., -0.0103,  0.0044,  0.0258],\n",
      "        [-0.0229, -0.0113, -0.0140,  ..., -0.0114,  0.0159, -0.0166],\n",
      "        ...,\n",
      "        [ 0.0027, -0.0155,  0.0123,  ..., -0.0020,  0.0017,  0.0140],\n",
      "        [-0.0162, -0.0173, -0.0252,  ...,  0.0149, -0.0302, -0.0037],\n",
      "        [ 0.0190,  0.0265,  0.0221,  ...,  0.0150,  0.0025,  0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0039,  0.0109,  0.0148,  ...,  0.0131, -0.0180, -0.0123],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0002, -0.0234,  0.0305,  ...,  0.0171, -0.0022, -0.0245],\n",
      "        [-0.0145, -0.0174, -0.0246,  ..., -0.0260,  0.0151,  0.0232],\n",
      "        [ 0.0210,  0.0048, -0.0199,  ..., -0.0055,  0.0282, -0.0278],\n",
      "        ...,\n",
      "        [-0.0198,  0.0053, -0.0132,  ...,  0.0053, -0.0197, -0.0249],\n",
      "        [ 0.0123, -0.0195,  0.0052,  ...,  0.0069,  0.0158,  0.0309],\n",
      "        [ 0.0223,  0.0260, -0.0011,  ..., -0.0065, -0.0214, -0.0308]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0122,  0.0199, -0.0274,  ...,  0.0102,  0.0276, -0.0299],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.4447e-02,  1.3317e-02, -1.1675e-02,  ...,  1.2466e-02,\n",
      "         -2.8715e-03, -1.9082e-03],\n",
      "        [ 5.2412e-03, -4.7804e-03,  1.1367e-02,  ..., -1.4205e-02,\n",
      "         -1.2430e-02, -1.1711e-02],\n",
      "        [-7.0830e-03,  6.4644e-03, -1.0714e-02,  ...,  3.4186e-03,\n",
      "          5.7424e-03,  1.2174e-02],\n",
      "        ...,\n",
      "        [ 1.1743e-02, -1.9802e-05,  5.8434e-03,  ...,  8.6743e-03,\n",
      "         -6.7520e-03,  1.4174e-02],\n",
      "        [-8.7649e-03,  1.3007e-02,  9.3680e-03,  ...,  5.5891e-03,\n",
      "         -1.4474e-02,  1.1184e-03],\n",
      "        [-1.5069e-02, -4.1434e-03,  7.9800e-03,  ..., -5.8487e-03,\n",
      "         -5.2553e-03,  1.2329e-02]], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0130,  0.0035,  0.0070,  ..., -0.0132, -0.0021, -0.0093],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0009,  0.0160, -0.0191,  ..., -0.0052, -0.0077,  0.0014],\n",
      "        [ 0.0239, -0.0190,  0.0028,  ..., -0.0046,  0.0101, -0.0146],\n",
      "        [ 0.0233,  0.0127,  0.0137,  ..., -0.0124, -0.0200,  0.0018],\n",
      "        ...,\n",
      "        [-0.0260,  0.0093,  0.0152,  ..., -0.0190, -0.0068, -0.0068],\n",
      "        [-0.0195,  0.0089, -0.0275,  ..., -0.0238,  0.0060, -0.0169],\n",
      "        [-0.0091, -0.0093,  0.0209,  ..., -0.0159,  0.0043,  0.0008]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0157, -0.0015, -0.0157,  ...,  0.0002, -0.0105,  0.0195],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0164,  0.0163, -0.0225,  ...,  0.0079,  0.0224,  0.0189],\n",
      "        [-0.0060, -0.0015, -0.0179,  ...,  0.0051, -0.0159,  0.0101],\n",
      "        [-0.0178, -0.0101, -0.0104,  ..., -0.0017,  0.0275, -0.0086],\n",
      "        ...,\n",
      "        [-0.0263,  0.0147,  0.0222,  ..., -0.0200,  0.0237,  0.0088],\n",
      "        [ 0.0247,  0.0143, -0.0228,  ...,  0.0075, -0.0111, -0.0286],\n",
      "        [-0.0230,  0.0062, -0.0034,  ..., -0.0078, -0.0017,  0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0069, -0.0189, -0.0183,  ...,  0.0081,  0.0005,  0.0034],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0197,  0.0064, -0.0084,  ...,  0.0270,  0.0091,  0.0200],\n",
      "        [ 0.0233, -0.0262,  0.0293,  ..., -0.0184, -0.0054,  0.0310],\n",
      "        [-0.0132,  0.0074,  0.0095,  ..., -0.0215, -0.0145,  0.0010],\n",
      "        ...,\n",
      "        [ 0.0109,  0.0291, -0.0104,  ..., -0.0149,  0.0128,  0.0018],\n",
      "        [-0.0056,  0.0151, -0.0300,  ...,  0.0138,  0.0254,  0.0203],\n",
      "        [ 0.0303,  0.0164, -0.0016,  ..., -0.0044, -0.0028, -0.0251]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0258,  0.0145,  0.0236,  ..., -0.0258, -0.0208,  0.0156],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0094, -0.0061, -0.0148,  ..., -0.0055,  0.0084, -0.0030],\n",
      "        [ 0.0266, -0.0187,  0.0094,  ..., -0.0103,  0.0044,  0.0258],\n",
      "        [-0.0229, -0.0113, -0.0140,  ..., -0.0114,  0.0159, -0.0166],\n",
      "        ...,\n",
      "        [ 0.0027, -0.0155,  0.0123,  ..., -0.0020,  0.0017,  0.0140],\n",
      "        [-0.0162, -0.0173, -0.0252,  ...,  0.0149, -0.0302, -0.0037],\n",
      "        [ 0.0190,  0.0265,  0.0221,  ...,  0.0150,  0.0025,  0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0039,  0.0109,  0.0148,  ...,  0.0131, -0.0180, -0.0123],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0002, -0.0234,  0.0305,  ...,  0.0171, -0.0022, -0.0245],\n",
      "        [-0.0145, -0.0174, -0.0246,  ..., -0.0260,  0.0151,  0.0232],\n",
      "        [ 0.0210,  0.0048, -0.0199,  ..., -0.0055,  0.0282, -0.0278],\n",
      "        ...,\n",
      "        [-0.0198,  0.0053, -0.0132,  ...,  0.0053, -0.0197, -0.0249],\n",
      "        [ 0.0123, -0.0195,  0.0052,  ...,  0.0069,  0.0158,  0.0309],\n",
      "        [ 0.0223,  0.0260, -0.0011,  ..., -0.0065, -0.0214, -0.0308]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0122,  0.0199, -0.0274,  ...,  0.0102,  0.0276, -0.0299],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.4447e-02,  1.3317e-02, -1.1675e-02,  ...,  1.2466e-02,\n",
      "         -2.8715e-03, -1.9082e-03],\n",
      "        [ 5.2412e-03, -4.7804e-03,  1.1367e-02,  ..., -1.4205e-02,\n",
      "         -1.2430e-02, -1.1711e-02],\n",
      "        [-7.0830e-03,  6.4644e-03, -1.0714e-02,  ...,  3.4186e-03,\n",
      "          5.7424e-03,  1.2174e-02],\n",
      "        ...,\n",
      "        [ 1.1743e-02, -1.9802e-05,  5.8434e-03,  ...,  8.6743e-03,\n",
      "         -6.7520e-03,  1.4174e-02],\n",
      "        [-8.7649e-03,  1.3007e-02,  9.3680e-03,  ...,  5.5891e-03,\n",
      "         -1.4474e-02,  1.1184e-03],\n",
      "        [-1.5069e-02, -4.1434e-03,  7.9800e-03,  ..., -5.8487e-03,\n",
      "         -5.2553e-03,  1.2329e-02]], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0130,  0.0035,  0.0070,  ..., -0.0132, -0.0021, -0.0093],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0009,  0.0160, -0.0191,  ..., -0.0052, -0.0077,  0.0014],\n",
      "        [ 0.0239, -0.0190,  0.0028,  ..., -0.0046,  0.0101, -0.0146],\n",
      "        [ 0.0233,  0.0127,  0.0137,  ..., -0.0124, -0.0200,  0.0018],\n",
      "        ...,\n",
      "        [-0.0260,  0.0093,  0.0152,  ..., -0.0190, -0.0068, -0.0068],\n",
      "        [-0.0195,  0.0089, -0.0275,  ..., -0.0238,  0.0060, -0.0169],\n",
      "        [-0.0091, -0.0093,  0.0209,  ..., -0.0159,  0.0043,  0.0008]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0157, -0.0015, -0.0157,  ...,  0.0002, -0.0105,  0.0195],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0164,  0.0163, -0.0225,  ...,  0.0079,  0.0224,  0.0189],\n",
      "        [-0.0060, -0.0015, -0.0179,  ...,  0.0051, -0.0159,  0.0101],\n",
      "        [-0.0178, -0.0101, -0.0104,  ..., -0.0017,  0.0275, -0.0086],\n",
      "        ...,\n",
      "        [-0.0263,  0.0147,  0.0222,  ..., -0.0200,  0.0237,  0.0088],\n",
      "        [ 0.0247,  0.0143, -0.0228,  ...,  0.0075, -0.0111, -0.0286],\n",
      "        [-0.0230,  0.0062, -0.0034,  ..., -0.0078, -0.0017,  0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0069, -0.0189, -0.0183,  ...,  0.0081,  0.0005,  0.0034],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0197,  0.0064, -0.0084,  ...,  0.0270,  0.0091,  0.0200],\n",
      "        [ 0.0233, -0.0262,  0.0293,  ..., -0.0184, -0.0054,  0.0310],\n",
      "        [-0.0132,  0.0074,  0.0095,  ..., -0.0215, -0.0145,  0.0010],\n",
      "        ...,\n",
      "        [ 0.0109,  0.0291, -0.0104,  ..., -0.0149,  0.0128,  0.0018],\n",
      "        [-0.0056,  0.0151, -0.0300,  ...,  0.0138,  0.0254,  0.0203],\n",
      "        [ 0.0303,  0.0164, -0.0016,  ..., -0.0044, -0.0028, -0.0251]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0258,  0.0145,  0.0236,  ..., -0.0258, -0.0208,  0.0156],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0094, -0.0061, -0.0148,  ..., -0.0055,  0.0084, -0.0030],\n",
      "        [ 0.0266, -0.0187,  0.0094,  ..., -0.0103,  0.0044,  0.0258],\n",
      "        [-0.0229, -0.0113, -0.0140,  ..., -0.0114,  0.0159, -0.0166],\n",
      "        ...,\n",
      "        [ 0.0027, -0.0155,  0.0123,  ..., -0.0020,  0.0017,  0.0140],\n",
      "        [-0.0162, -0.0173, -0.0252,  ...,  0.0149, -0.0302, -0.0037],\n",
      "        [ 0.0190,  0.0265,  0.0221,  ...,  0.0150,  0.0025,  0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0039,  0.0109,  0.0148,  ...,  0.0131, -0.0180, -0.0123],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0002, -0.0234,  0.0305,  ...,  0.0171, -0.0022, -0.0245],\n",
      "        [-0.0145, -0.0174, -0.0246,  ..., -0.0260,  0.0151,  0.0232],\n",
      "        [ 0.0210,  0.0048, -0.0199,  ..., -0.0055,  0.0282, -0.0278],\n",
      "        ...,\n",
      "        [-0.0198,  0.0053, -0.0132,  ...,  0.0053, -0.0197, -0.0249],\n",
      "        [ 0.0123, -0.0195,  0.0052,  ...,  0.0069,  0.0158,  0.0309],\n",
      "        [ 0.0223,  0.0260, -0.0011,  ..., -0.0065, -0.0214, -0.0308]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0122,  0.0199, -0.0274,  ...,  0.0102,  0.0276, -0.0299],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.4447e-02,  1.3317e-02, -1.1675e-02,  ...,  1.2466e-02,\n",
      "         -2.8715e-03, -1.9082e-03],\n",
      "        [ 5.2412e-03, -4.7804e-03,  1.1367e-02,  ..., -1.4205e-02,\n",
      "         -1.2430e-02, -1.1711e-02],\n",
      "        [-7.0830e-03,  6.4644e-03, -1.0714e-02,  ...,  3.4186e-03,\n",
      "          5.7424e-03,  1.2174e-02],\n",
      "        ...,\n",
      "        [ 1.1743e-02, -1.9802e-05,  5.8434e-03,  ...,  8.6743e-03,\n",
      "         -6.7520e-03,  1.4174e-02],\n",
      "        [-8.7649e-03,  1.3007e-02,  9.3680e-03,  ...,  5.5891e-03,\n",
      "         -1.4474e-02,  1.1184e-03],\n",
      "        [-1.5069e-02, -4.1434e-03,  7.9800e-03,  ..., -5.8487e-03,\n",
      "         -5.2553e-03,  1.2329e-02]], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0130,  0.0035,  0.0070,  ..., -0.0132, -0.0021, -0.0093],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0009,  0.0160, -0.0191,  ..., -0.0052, -0.0077,  0.0014],\n",
      "        [ 0.0239, -0.0190,  0.0028,  ..., -0.0046,  0.0101, -0.0146],\n",
      "        [ 0.0233,  0.0127,  0.0137,  ..., -0.0124, -0.0200,  0.0018],\n",
      "        ...,\n",
      "        [-0.0260,  0.0093,  0.0152,  ..., -0.0190, -0.0068, -0.0068],\n",
      "        [-0.0195,  0.0089, -0.0275,  ..., -0.0238,  0.0060, -0.0169],\n",
      "        [-0.0091, -0.0093,  0.0209,  ..., -0.0159,  0.0043,  0.0008]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0157, -0.0015, -0.0157,  ...,  0.0002, -0.0105,  0.0195],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0164,  0.0163, -0.0225,  ...,  0.0079,  0.0224,  0.0189],\n",
      "        [-0.0060, -0.0015, -0.0179,  ...,  0.0051, -0.0159,  0.0101],\n",
      "        [-0.0178, -0.0101, -0.0104,  ..., -0.0017,  0.0275, -0.0086],\n",
      "        ...,\n",
      "        [-0.0263,  0.0147,  0.0222,  ..., -0.0200,  0.0237,  0.0088],\n",
      "        [ 0.0247,  0.0143, -0.0228,  ...,  0.0075, -0.0111, -0.0286],\n",
      "        [-0.0230,  0.0062, -0.0034,  ..., -0.0078, -0.0017,  0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0069, -0.0189, -0.0183,  ...,  0.0081,  0.0005,  0.0034],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0094, -0.0061, -0.0148,  ..., -0.0055,  0.0084, -0.0030],\n",
      "        [ 0.0266, -0.0187,  0.0094,  ..., -0.0103,  0.0044,  0.0258],\n",
      "        [-0.0229, -0.0113, -0.0140,  ..., -0.0114,  0.0159, -0.0166],\n",
      "        ...,\n",
      "        [ 0.0027, -0.0155,  0.0123,  ..., -0.0020,  0.0017,  0.0140],\n",
      "        [-0.0162, -0.0173, -0.0252,  ...,  0.0149, -0.0302, -0.0037],\n",
      "        [ 0.0190,  0.0265,  0.0221,  ...,  0.0150,  0.0025,  0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0039,  0.0109,  0.0148,  ...,  0.0131, -0.0180, -0.0123],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0002, -0.0234,  0.0305,  ...,  0.0171, -0.0022, -0.0245],\n",
      "        [-0.0145, -0.0174, -0.0246,  ..., -0.0260,  0.0151,  0.0232],\n",
      "        [ 0.0210,  0.0048, -0.0199,  ..., -0.0055,  0.0282, -0.0278],\n",
      "        ...,\n",
      "        [-0.0198,  0.0053, -0.0132,  ...,  0.0053, -0.0197, -0.0249],\n",
      "        [ 0.0123, -0.0195,  0.0052,  ...,  0.0069,  0.0158,  0.0309],\n",
      "        [ 0.0223,  0.0260, -0.0011,  ..., -0.0065, -0.0214, -0.0308]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0122,  0.0199, -0.0274,  ...,  0.0102,  0.0276, -0.0299],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.4447e-02,  1.3317e-02, -1.1675e-02,  ...,  1.2466e-02,\n",
      "         -2.8715e-03, -1.9082e-03],\n",
      "        [ 5.2412e-03, -4.7804e-03,  1.1367e-02,  ..., -1.4205e-02,\n",
      "         -1.2430e-02, -1.1711e-02],\n",
      "        [-7.0830e-03,  6.4644e-03, -1.0714e-02,  ...,  3.4186e-03,\n",
      "          5.7424e-03,  1.2174e-02],\n",
      "        ...,\n",
      "        [ 1.1743e-02, -1.9802e-05,  5.8434e-03,  ...,  8.6743e-03,\n",
      "         -6.7520e-03,  1.4174e-02],\n",
      "        [-8.7649e-03,  1.3007e-02,  9.3680e-03,  ...,  5.5891e-03,\n",
      "         -1.4474e-02,  1.1184e-03],\n",
      "        [-1.5069e-02, -4.1434e-03,  7.9800e-03,  ..., -5.8487e-03,\n",
      "         -5.2553e-03,  1.2329e-02]], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0130,  0.0035,  0.0070,  ..., -0.0132, -0.0021, -0.0093],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0009,  0.0160, -0.0191,  ..., -0.0052, -0.0077,  0.0014],\n",
      "        [ 0.0239, -0.0190,  0.0028,  ..., -0.0046,  0.0101, -0.0146],\n",
      "        [ 0.0233,  0.0127,  0.0137,  ..., -0.0124, -0.0200,  0.0018],\n",
      "        ...,\n",
      "        [-0.0260,  0.0093,  0.0152,  ..., -0.0190, -0.0068, -0.0068],\n",
      "        [-0.0195,  0.0089, -0.0275,  ..., -0.0238,  0.0060, -0.0169],\n",
      "        [-0.0091, -0.0093,  0.0209,  ..., -0.0159,  0.0043,  0.0008]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0157, -0.0015, -0.0157,  ...,  0.0002, -0.0105,  0.0195],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0164,  0.0163, -0.0225,  ...,  0.0079,  0.0224,  0.0189],\n",
      "        [-0.0060, -0.0015, -0.0179,  ...,  0.0051, -0.0159,  0.0101],\n",
      "        [-0.0178, -0.0101, -0.0104,  ..., -0.0017,  0.0275, -0.0086],\n",
      "        ...,\n",
      "        [-0.0263,  0.0147,  0.0222,  ..., -0.0200,  0.0237,  0.0088],\n",
      "        [ 0.0247,  0.0143, -0.0228,  ...,  0.0075, -0.0111, -0.0286],\n",
      "        [-0.0230,  0.0062, -0.0034,  ..., -0.0078, -0.0017,  0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0069, -0.0189, -0.0183,  ...,  0.0081,  0.0005,  0.0034],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0002, -0.0234,  0.0305,  ...,  0.0171, -0.0022, -0.0245],\n",
      "        [-0.0145, -0.0174, -0.0246,  ..., -0.0260,  0.0151,  0.0232],\n",
      "        [ 0.0210,  0.0048, -0.0199,  ..., -0.0055,  0.0282, -0.0278],\n",
      "        ...,\n",
      "        [-0.0198,  0.0053, -0.0132,  ...,  0.0053, -0.0197, -0.0249],\n",
      "        [ 0.0123, -0.0195,  0.0052,  ...,  0.0069,  0.0158,  0.0309],\n",
      "        [ 0.0223,  0.0260, -0.0011,  ..., -0.0065, -0.0214, -0.0308]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0122,  0.0199, -0.0274,  ...,  0.0102,  0.0276, -0.0299],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.4447e-02,  1.3317e-02, -1.1675e-02,  ...,  1.2466e-02,\n",
      "         -2.8715e-03, -1.9082e-03],\n",
      "        [ 5.2412e-03, -4.7804e-03,  1.1367e-02,  ..., -1.4205e-02,\n",
      "         -1.2430e-02, -1.1711e-02],\n",
      "        [-7.0830e-03,  6.4644e-03, -1.0714e-02,  ...,  3.4186e-03,\n",
      "          5.7424e-03,  1.2174e-02],\n",
      "        ...,\n",
      "        [ 1.1743e-02, -1.9802e-05,  5.8434e-03,  ...,  8.6743e-03,\n",
      "         -6.7520e-03,  1.4174e-02],\n",
      "        [-8.7649e-03,  1.3007e-02,  9.3680e-03,  ...,  5.5891e-03,\n",
      "         -1.4474e-02,  1.1184e-03],\n",
      "        [-1.5069e-02, -4.1434e-03,  7.9800e-03,  ..., -5.8487e-03,\n",
      "         -5.2553e-03,  1.2329e-02]], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0130,  0.0035,  0.0070,  ..., -0.0132, -0.0021, -0.0093],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0009,  0.0160, -0.0191,  ..., -0.0052, -0.0077,  0.0014],\n",
      "        [ 0.0239, -0.0190,  0.0028,  ..., -0.0046,  0.0101, -0.0146],\n",
      "        [ 0.0233,  0.0127,  0.0137,  ..., -0.0124, -0.0200,  0.0018],\n",
      "        ...,\n",
      "        [-0.0260,  0.0093,  0.0152,  ..., -0.0190, -0.0068, -0.0068],\n",
      "        [-0.0195,  0.0089, -0.0275,  ..., -0.0238,  0.0060, -0.0169],\n",
      "        [-0.0091, -0.0093,  0.0209,  ..., -0.0159,  0.0043,  0.0008]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0157, -0.0015, -0.0157,  ...,  0.0002, -0.0105,  0.0195],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0164,  0.0163, -0.0225,  ...,  0.0079,  0.0224,  0.0189],\n",
      "        [-0.0060, -0.0015, -0.0179,  ...,  0.0051, -0.0159,  0.0101],\n",
      "        [-0.0178, -0.0101, -0.0104,  ..., -0.0017,  0.0275, -0.0086],\n",
      "        ...,\n",
      "        [-0.0263,  0.0147,  0.0222,  ..., -0.0200,  0.0237,  0.0088],\n",
      "        [ 0.0247,  0.0143, -0.0228,  ...,  0.0075, -0.0111, -0.0286],\n",
      "        [-0.0230,  0.0062, -0.0034,  ..., -0.0078, -0.0017,  0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0069, -0.0189, -0.0183,  ...,  0.0081,  0.0005,  0.0034],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0002, -0.0234,  0.0305,  ...,  0.0171, -0.0022, -0.0245],\n",
      "        [-0.0145, -0.0174, -0.0246,  ..., -0.0260,  0.0151,  0.0232],\n",
      "        [ 0.0210,  0.0048, -0.0199,  ..., -0.0055,  0.0282, -0.0278],\n",
      "        ...,\n",
      "        [-0.0198,  0.0053, -0.0132,  ...,  0.0053, -0.0197, -0.0249],\n",
      "        [ 0.0123, -0.0195,  0.0052,  ...,  0.0069,  0.0158,  0.0309],\n",
      "        [ 0.0223,  0.0260, -0.0011,  ..., -0.0065, -0.0214, -0.0308]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0122,  0.0199, -0.0274,  ...,  0.0102,  0.0276, -0.0299],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.4447e-02,  1.3317e-02, -1.1675e-02,  ...,  1.2466e-02,\n",
      "         -2.8715e-03, -1.9082e-03],\n",
      "        [ 5.2412e-03, -4.7804e-03,  1.1367e-02,  ..., -1.4205e-02,\n",
      "         -1.2430e-02, -1.1711e-02],\n",
      "        [-7.0830e-03,  6.4644e-03, -1.0714e-02,  ...,  3.4186e-03,\n",
      "          5.7424e-03,  1.2174e-02],\n",
      "        ...,\n",
      "        [ 1.1743e-02, -1.9802e-05,  5.8434e-03,  ...,  8.6743e-03,\n",
      "         -6.7520e-03,  1.4174e-02],\n",
      "        [-8.7649e-03,  1.3007e-02,  9.3680e-03,  ...,  5.5891e-03,\n",
      "         -1.4474e-02,  1.1184e-03],\n",
      "        [-1.5069e-02, -4.1434e-03,  7.9800e-03,  ..., -5.8487e-03,\n",
      "         -5.2553e-03,  1.2329e-02]], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0130,  0.0035,  0.0070,  ..., -0.0132, -0.0021, -0.0093],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0009,  0.0160, -0.0191,  ..., -0.0052, -0.0077,  0.0014],\n",
      "        [ 0.0239, -0.0190,  0.0028,  ..., -0.0046,  0.0101, -0.0146],\n",
      "        [ 0.0233,  0.0127,  0.0137,  ..., -0.0124, -0.0200,  0.0018],\n",
      "        ...,\n",
      "        [-0.0260,  0.0093,  0.0152,  ..., -0.0190, -0.0068, -0.0068],\n",
      "        [-0.0195,  0.0089, -0.0275,  ..., -0.0238,  0.0060, -0.0169],\n",
      "        [-0.0091, -0.0093,  0.0209,  ..., -0.0159,  0.0043,  0.0008]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0157, -0.0015, -0.0157,  ...,  0.0002, -0.0105,  0.0195],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0164,  0.0163, -0.0225,  ...,  0.0079,  0.0224,  0.0189],\n",
      "        [-0.0060, -0.0015, -0.0179,  ...,  0.0051, -0.0159,  0.0101],\n",
      "        [-0.0178, -0.0101, -0.0104,  ..., -0.0017,  0.0275, -0.0086],\n",
      "        ...,\n",
      "        [-0.0263,  0.0147,  0.0222,  ..., -0.0200,  0.0237,  0.0088],\n",
      "        [ 0.0247,  0.0143, -0.0228,  ...,  0.0075, -0.0111, -0.0286],\n",
      "        [-0.0230,  0.0062, -0.0034,  ..., -0.0078, -0.0017,  0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0069, -0.0189, -0.0183,  ...,  0.0081,  0.0005,  0.0034],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0002, -0.0234,  0.0305,  ...,  0.0171, -0.0022, -0.0245],\n",
      "        [-0.0145, -0.0174, -0.0246,  ..., -0.0260,  0.0151,  0.0232],\n",
      "        [ 0.0210,  0.0048, -0.0199,  ..., -0.0055,  0.0282, -0.0278],\n",
      "        ...,\n",
      "        [-0.0198,  0.0053, -0.0132,  ...,  0.0053, -0.0197, -0.0249],\n",
      "        [ 0.0123, -0.0195,  0.0052,  ...,  0.0069,  0.0158,  0.0309],\n",
      "        [ 0.0223,  0.0260, -0.0011,  ..., -0.0065, -0.0214, -0.0308]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0122,  0.0199, -0.0274,  ...,  0.0102,  0.0276, -0.0299],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.4447e-02,  1.3317e-02, -1.1675e-02,  ...,  1.2466e-02,\n",
      "         -2.8715e-03, -1.9082e-03],\n",
      "        [ 5.2412e-03, -4.7804e-03,  1.1367e-02,  ..., -1.4205e-02,\n",
      "         -1.2430e-02, -1.1711e-02],\n",
      "        [-7.0830e-03,  6.4644e-03, -1.0714e-02,  ...,  3.4186e-03,\n",
      "          5.7424e-03,  1.2174e-02],\n",
      "        ...,\n",
      "        [ 1.1743e-02, -1.9802e-05,  5.8434e-03,  ...,  8.6743e-03,\n",
      "         -6.7520e-03,  1.4174e-02],\n",
      "        [-8.7649e-03,  1.3007e-02,  9.3680e-03,  ...,  5.5891e-03,\n",
      "         -1.4474e-02,  1.1184e-03],\n",
      "        [-1.5069e-02, -4.1434e-03,  7.9800e-03,  ..., -5.8487e-03,\n",
      "         -5.2553e-03,  1.2329e-02]], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0130,  0.0035,  0.0070,  ..., -0.0132, -0.0021, -0.0093],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0009,  0.0160, -0.0191,  ..., -0.0052, -0.0077,  0.0014],\n",
      "        [ 0.0239, -0.0190,  0.0028,  ..., -0.0046,  0.0101, -0.0146],\n",
      "        [ 0.0233,  0.0127,  0.0137,  ..., -0.0124, -0.0200,  0.0018],\n",
      "        ...,\n",
      "        [-0.0260,  0.0093,  0.0152,  ..., -0.0190, -0.0068, -0.0068],\n",
      "        [-0.0195,  0.0089, -0.0275,  ..., -0.0238,  0.0060, -0.0169],\n",
      "        [-0.0091, -0.0093,  0.0209,  ..., -0.0159,  0.0043,  0.0008]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0157, -0.0015, -0.0157,  ...,  0.0002, -0.0105,  0.0195],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0164,  0.0163, -0.0225,  ...,  0.0079,  0.0224,  0.0189],\n",
      "        [-0.0060, -0.0015, -0.0179,  ...,  0.0051, -0.0159,  0.0101],\n",
      "        [-0.0178, -0.0101, -0.0104,  ..., -0.0017,  0.0275, -0.0086],\n",
      "        ...,\n",
      "        [-0.0263,  0.0147,  0.0222,  ..., -0.0200,  0.0237,  0.0088],\n",
      "        [ 0.0247,  0.0143, -0.0228,  ...,  0.0075, -0.0111, -0.0286],\n",
      "        [-0.0230,  0.0062, -0.0034,  ..., -0.0078, -0.0017,  0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0069, -0.0189, -0.0183,  ...,  0.0081,  0.0005,  0.0034],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.4447e-02,  1.3317e-02, -1.1675e-02,  ...,  1.2466e-02,\n",
      "         -2.8715e-03, -1.9082e-03],\n",
      "        [ 5.2412e-03, -4.7804e-03,  1.1367e-02,  ..., -1.4205e-02,\n",
      "         -1.2430e-02, -1.1711e-02],\n",
      "        [-7.0830e-03,  6.4644e-03, -1.0714e-02,  ...,  3.4186e-03,\n",
      "          5.7424e-03,  1.2174e-02],\n",
      "        ...,\n",
      "        [ 1.1743e-02, -1.9802e-05,  5.8434e-03,  ...,  8.6743e-03,\n",
      "         -6.7520e-03,  1.4174e-02],\n",
      "        [-8.7649e-03,  1.3007e-02,  9.3680e-03,  ...,  5.5891e-03,\n",
      "         -1.4474e-02,  1.1184e-03],\n",
      "        [-1.5069e-02, -4.1434e-03,  7.9800e-03,  ..., -5.8487e-03,\n",
      "         -5.2553e-03,  1.2329e-02]], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0130,  0.0035,  0.0070,  ..., -0.0132, -0.0021, -0.0093],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0009,  0.0160, -0.0191,  ..., -0.0052, -0.0077,  0.0014],\n",
      "        [ 0.0239, -0.0190,  0.0028,  ..., -0.0046,  0.0101, -0.0146],\n",
      "        [ 0.0233,  0.0127,  0.0137,  ..., -0.0124, -0.0200,  0.0018],\n",
      "        ...,\n",
      "        [-0.0260,  0.0093,  0.0152,  ..., -0.0190, -0.0068, -0.0068],\n",
      "        [-0.0195,  0.0089, -0.0275,  ..., -0.0238,  0.0060, -0.0169],\n",
      "        [-0.0091, -0.0093,  0.0209,  ..., -0.0159,  0.0043,  0.0008]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0157, -0.0015, -0.0157,  ...,  0.0002, -0.0105,  0.0195],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0164,  0.0163, -0.0225,  ...,  0.0079,  0.0224,  0.0189],\n",
      "        [-0.0060, -0.0015, -0.0179,  ...,  0.0051, -0.0159,  0.0101],\n",
      "        [-0.0178, -0.0101, -0.0104,  ..., -0.0017,  0.0275, -0.0086],\n",
      "        ...,\n",
      "        [-0.0263,  0.0147,  0.0222,  ..., -0.0200,  0.0237,  0.0088],\n",
      "        [ 0.0247,  0.0143, -0.0228,  ...,  0.0075, -0.0111, -0.0286],\n",
      "        [-0.0230,  0.0062, -0.0034,  ..., -0.0078, -0.0017,  0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0069, -0.0189, -0.0183,  ...,  0.0081,  0.0005,  0.0034],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.4447e-02,  1.3317e-02, -1.1675e-02,  ...,  1.2466e-02,\n",
      "         -2.8715e-03, -1.9082e-03],\n",
      "        [ 5.2412e-03, -4.7804e-03,  1.1367e-02,  ..., -1.4205e-02,\n",
      "         -1.2430e-02, -1.1711e-02],\n",
      "        [-7.0830e-03,  6.4644e-03, -1.0714e-02,  ...,  3.4186e-03,\n",
      "          5.7424e-03,  1.2174e-02],\n",
      "        ...,\n",
      "        [ 1.1743e-02, -1.9802e-05,  5.8434e-03,  ...,  8.6743e-03,\n",
      "         -6.7520e-03,  1.4174e-02],\n",
      "        [-8.7649e-03,  1.3007e-02,  9.3680e-03,  ...,  5.5891e-03,\n",
      "         -1.4474e-02,  1.1184e-03],\n",
      "        [-1.5069e-02, -4.1434e-03,  7.9800e-03,  ..., -5.8487e-03,\n",
      "         -5.2553e-03,  1.2329e-02]], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0130,  0.0035,  0.0070,  ..., -0.0132, -0.0021, -0.0093],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0009,  0.0160, -0.0191,  ..., -0.0052, -0.0077,  0.0014],\n",
      "        [ 0.0239, -0.0190,  0.0028,  ..., -0.0046,  0.0101, -0.0146],\n",
      "        [ 0.0233,  0.0127,  0.0137,  ..., -0.0124, -0.0200,  0.0018],\n",
      "        ...,\n",
      "        [-0.0260,  0.0093,  0.0152,  ..., -0.0190, -0.0068, -0.0068],\n",
      "        [-0.0195,  0.0089, -0.0275,  ..., -0.0238,  0.0060, -0.0169],\n",
      "        [-0.0091, -0.0093,  0.0209,  ..., -0.0159,  0.0043,  0.0008]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0157, -0.0015, -0.0157,  ...,  0.0002, -0.0105,  0.0195],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0164,  0.0163, -0.0225,  ...,  0.0079,  0.0224,  0.0189],\n",
      "        [-0.0060, -0.0015, -0.0179,  ...,  0.0051, -0.0159,  0.0101],\n",
      "        [-0.0178, -0.0101, -0.0104,  ..., -0.0017,  0.0275, -0.0086],\n",
      "        ...,\n",
      "        [-0.0263,  0.0147,  0.0222,  ..., -0.0200,  0.0237,  0.0088],\n",
      "        [ 0.0247,  0.0143, -0.0228,  ...,  0.0075, -0.0111, -0.0286],\n",
      "        [-0.0230,  0.0062, -0.0034,  ..., -0.0078, -0.0017,  0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0069, -0.0189, -0.0183,  ...,  0.0081,  0.0005,  0.0034],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0009,  0.0160, -0.0191,  ..., -0.0052, -0.0077,  0.0014],\n",
      "        [ 0.0239, -0.0190,  0.0028,  ..., -0.0046,  0.0101, -0.0146],\n",
      "        [ 0.0233,  0.0127,  0.0137,  ..., -0.0124, -0.0200,  0.0018],\n",
      "        ...,\n",
      "        [-0.0260,  0.0093,  0.0152,  ..., -0.0190, -0.0068, -0.0068],\n",
      "        [-0.0195,  0.0089, -0.0275,  ..., -0.0238,  0.0060, -0.0169],\n",
      "        [-0.0091, -0.0093,  0.0209,  ..., -0.0159,  0.0043,  0.0008]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0157, -0.0015, -0.0157,  ...,  0.0002, -0.0105,  0.0195],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0164,  0.0163, -0.0225,  ...,  0.0079,  0.0224,  0.0189],\n",
      "        [-0.0060, -0.0015, -0.0179,  ...,  0.0051, -0.0159,  0.0101],\n",
      "        [-0.0178, -0.0101, -0.0104,  ..., -0.0017,  0.0275, -0.0086],\n",
      "        ...,\n",
      "        [-0.0263,  0.0147,  0.0222,  ..., -0.0200,  0.0237,  0.0088],\n",
      "        [ 0.0247,  0.0143, -0.0228,  ...,  0.0075, -0.0111, -0.0286],\n",
      "        [-0.0230,  0.0062, -0.0034,  ..., -0.0078, -0.0017,  0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0069, -0.0189, -0.0183,  ...,  0.0081,  0.0005,  0.0034],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0009,  0.0160, -0.0191,  ..., -0.0052, -0.0077,  0.0014],\n",
      "        [ 0.0239, -0.0190,  0.0028,  ..., -0.0046,  0.0101, -0.0146],\n",
      "        [ 0.0233,  0.0127,  0.0137,  ..., -0.0124, -0.0200,  0.0018],\n",
      "        ...,\n",
      "        [-0.0260,  0.0093,  0.0152,  ..., -0.0190, -0.0068, -0.0068],\n",
      "        [-0.0195,  0.0089, -0.0275,  ..., -0.0238,  0.0060, -0.0169],\n",
      "        [-0.0091, -0.0093,  0.0209,  ..., -0.0159,  0.0043,  0.0008]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0157, -0.0015, -0.0157,  ...,  0.0002, -0.0105,  0.0195],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0164,  0.0163, -0.0225,  ...,  0.0079,  0.0224,  0.0189],\n",
      "        [-0.0060, -0.0015, -0.0179,  ...,  0.0051, -0.0159,  0.0101],\n",
      "        [-0.0178, -0.0101, -0.0104,  ..., -0.0017,  0.0275, -0.0086],\n",
      "        ...,\n",
      "        [-0.0263,  0.0147,  0.0222,  ..., -0.0200,  0.0237,  0.0088],\n",
      "        [ 0.0247,  0.0143, -0.0228,  ...,  0.0075, -0.0111, -0.0286],\n",
      "        [-0.0230,  0.0062, -0.0034,  ..., -0.0078, -0.0017,  0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0069, -0.0189, -0.0183,  ...,  0.0081,  0.0005,  0.0034],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0009,  0.0160, -0.0191,  ..., -0.0052, -0.0077,  0.0014],\n",
      "        [ 0.0239, -0.0190,  0.0028,  ..., -0.0046,  0.0101, -0.0146],\n",
      "        [ 0.0233,  0.0127,  0.0137,  ..., -0.0124, -0.0200,  0.0018],\n",
      "        ...,\n",
      "        [-0.0260,  0.0093,  0.0152,  ..., -0.0190, -0.0068, -0.0068],\n",
      "        [-0.0195,  0.0089, -0.0275,  ..., -0.0238,  0.0060, -0.0169],\n",
      "        [-0.0091, -0.0093,  0.0209,  ..., -0.0159,  0.0043,  0.0008]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0157, -0.0015, -0.0157,  ...,  0.0002, -0.0105,  0.0195],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0164,  0.0163, -0.0225,  ...,  0.0079,  0.0224,  0.0189],\n",
      "        [-0.0060, -0.0015, -0.0179,  ...,  0.0051, -0.0159,  0.0101],\n",
      "        [-0.0178, -0.0101, -0.0104,  ..., -0.0017,  0.0275, -0.0086],\n",
      "        ...,\n",
      "        [-0.0263,  0.0147,  0.0222,  ..., -0.0200,  0.0237,  0.0088],\n",
      "        [ 0.0247,  0.0143, -0.0228,  ...,  0.0075, -0.0111, -0.0286],\n",
      "        [-0.0230,  0.0062, -0.0034,  ..., -0.0078, -0.0017,  0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0069, -0.0189, -0.0183,  ...,  0.0081,  0.0005,  0.0034],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0009,  0.0160, -0.0191,  ..., -0.0052, -0.0077,  0.0014],\n",
      "        [ 0.0239, -0.0190,  0.0028,  ..., -0.0046,  0.0101, -0.0146],\n",
      "        [ 0.0233,  0.0127,  0.0137,  ..., -0.0124, -0.0200,  0.0018],\n",
      "        ...,\n",
      "        [-0.0260,  0.0093,  0.0152,  ..., -0.0190, -0.0068, -0.0068],\n",
      "        [-0.0195,  0.0089, -0.0275,  ..., -0.0238,  0.0060, -0.0169],\n",
      "        [-0.0091, -0.0093,  0.0209,  ..., -0.0159,  0.0043,  0.0008]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0157, -0.0015, -0.0157,  ...,  0.0002, -0.0105,  0.0195],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0164,  0.0163, -0.0225,  ...,  0.0079,  0.0224,  0.0189],\n",
      "        [-0.0060, -0.0015, -0.0179,  ...,  0.0051, -0.0159,  0.0101],\n",
      "        [-0.0178, -0.0101, -0.0104,  ..., -0.0017,  0.0275, -0.0086],\n",
      "        ...,\n",
      "        [-0.0263,  0.0147,  0.0222,  ..., -0.0200,  0.0237,  0.0088],\n",
      "        [ 0.0247,  0.0143, -0.0228,  ...,  0.0075, -0.0111, -0.0286],\n",
      "        [-0.0230,  0.0062, -0.0034,  ..., -0.0078, -0.0017,  0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0069, -0.0189, -0.0183,  ...,  0.0081,  0.0005,  0.0034],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0009,  0.0160, -0.0191,  ..., -0.0052, -0.0077,  0.0014],\n",
      "        [ 0.0239, -0.0190,  0.0028,  ..., -0.0046,  0.0101, -0.0146],\n",
      "        [ 0.0233,  0.0127,  0.0137,  ..., -0.0124, -0.0200,  0.0018],\n",
      "        ...,\n",
      "        [-0.0260,  0.0093,  0.0152,  ..., -0.0190, -0.0068, -0.0068],\n",
      "        [-0.0195,  0.0089, -0.0275,  ..., -0.0238,  0.0060, -0.0169],\n",
      "        [-0.0091, -0.0093,  0.0209,  ..., -0.0159,  0.0043,  0.0008]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0157, -0.0015, -0.0157,  ...,  0.0002, -0.0105,  0.0195],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0164,  0.0163, -0.0225,  ...,  0.0079,  0.0224,  0.0189],\n",
      "        [-0.0060, -0.0015, -0.0179,  ...,  0.0051, -0.0159,  0.0101],\n",
      "        [-0.0178, -0.0101, -0.0104,  ..., -0.0017,  0.0275, -0.0086],\n",
      "        ...,\n",
      "        [-0.0263,  0.0147,  0.0222,  ..., -0.0200,  0.0237,  0.0088],\n",
      "        [ 0.0247,  0.0143, -0.0228,  ...,  0.0075, -0.0111, -0.0286],\n",
      "        [-0.0230,  0.0062, -0.0034,  ..., -0.0078, -0.0017,  0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0069, -0.0189, -0.0183,  ...,  0.0081,  0.0005,  0.0034],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0164,  0.0163, -0.0225,  ...,  0.0079,  0.0224,  0.0189],\n",
      "        [-0.0060, -0.0015, -0.0179,  ...,  0.0051, -0.0159,  0.0101],\n",
      "        [-0.0178, -0.0101, -0.0104,  ..., -0.0017,  0.0275, -0.0086],\n",
      "        ...,\n",
      "        [-0.0263,  0.0147,  0.0222,  ..., -0.0200,  0.0237,  0.0088],\n",
      "        [ 0.0247,  0.0143, -0.0228,  ...,  0.0075, -0.0111, -0.0286],\n",
      "        [-0.0230,  0.0062, -0.0034,  ..., -0.0078, -0.0017,  0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0069, -0.0189, -0.0183,  ...,  0.0081,  0.0005,  0.0034],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0175,  0.0183,  ..., -0.0126,  0.0264, -0.0295],\n",
      "        [-0.0075,  0.0234, -0.0064,  ..., -0.0005, -0.0046,  0.0250],\n",
      "        [ 0.0232,  0.0214,  0.0170,  ..., -0.0077, -0.0253,  0.0151],\n",
      "        ...,\n",
      "        [-0.0030,  0.0152, -0.0109,  ..., -0.0156, -0.0234, -0.0210],\n",
      "        [-0.0216,  0.0014,  0.0271,  ...,  0.0034, -0.0187, -0.0005],\n",
      "        [ 0.0299,  0.0030,  0.0140,  ...,  0.0021, -0.0212, -0.0231]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0.0097, 0.0286, 0.0033,  ..., 0.0249, 0.0177, 0.0025],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0020, -0.0047,  0.0045,  ...,  0.0058, -0.0134, -0.0057],\n",
      "        [ 0.0099, -0.0020, -0.0052,  ..., -0.0014,  0.0073, -0.0144],\n",
      "        [-0.0118,  0.0020,  0.0138,  ..., -0.0106,  0.0149,  0.0040],\n",
      "        ...,\n",
      "        [-0.0063, -0.0103, -0.0153,  ..., -0.0055, -0.0026, -0.0025],\n",
      "        [ 0.0007,  0.0138, -0.0105,  ..., -0.0043,  0.0094,  0.0044],\n",
      "        [ 0.0127, -0.0104,  0.0123,  ..., -0.0020, -0.0120,  0.0125]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-1.1582e-02, -8.8226e-03, -3.2750e-03,  ...,  8.7578e-03,\n",
      "         4.1440e-03, -8.1202e-05], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0085,  0.0307,  0.0312,  ..., -0.0182,  0.0196, -0.0153],\n",
      "        [ 0.0035,  0.0079, -0.0109,  ..., -0.0248, -0.0255, -0.0279],\n",
      "        [ 0.0045, -0.0169, -0.0226,  ...,  0.0188, -0.0216,  0.0237],\n",
      "        ...,\n",
      "        [-0.0146,  0.0112, -0.0103,  ...,  0.0085,  0.0307, -0.0231],\n",
      "        [ 0.0240, -0.0299,  0.0228,  ...,  0.0060,  0.0132, -0.0225],\n",
      "        [-0.0215, -0.0228, -0.0303,  ...,  0.0234, -0.0222, -0.0017]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0161,  0.0022,  0.0276,  ...,  0.0044, -0.0303, -0.0186],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0070,  0.0051, -0.0238,  ..., -0.0280,  0.0213,  0.0035],\n",
      "        [ 0.0100, -0.0121, -0.0284,  ...,  0.0172, -0.0191, -0.0218],\n",
      "        [-0.0187,  0.0258,  0.0311,  ...,  0.0198,  0.0011, -0.0294],\n",
      "        ...,\n",
      "        [ 0.0126,  0.0091, -0.0075,  ...,  0.0053,  0.0035, -0.0109],\n",
      "        [ 0.0172, -0.0111,  0.0081,  ..., -0.0058, -0.0162,  0.0308],\n",
      "        [-0.0116,  0.0143,  0.0227,  ..., -0.0082,  0.0139, -0.0289]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0255, -0.0189,  0.0119,  ..., -0.0013,  0.0257, -0.0271],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.1136e-02,  2.6136e-02, -2.0340e-02,  ..., -1.3117e-02,\n",
      "         -2.3519e-02, -1.0797e-02],\n",
      "        [ 1.4742e-02,  1.6409e-02,  9.5492e-03,  ...,  1.5666e-02,\n",
      "         -3.5950e-03, -5.1770e-03],\n",
      "        [ 2.2380e-02, -2.1931e-02, -9.6164e-03,  ...,  1.3517e-03,\n",
      "         -9.6869e-03, -7.8350e-03],\n",
      "        ...,\n",
      "        [ 3.9082e-03,  2.8970e-02,  6.8248e-03,  ..., -1.6036e-03,\n",
      "         -4.4849e-05, -8.6453e-03],\n",
      "        [-2.3279e-02,  3.2799e-03, -3.1154e-02,  ..., -1.1178e-02,\n",
      "         -2.6620e-02, -7.3609e-03],\n",
      "        [-5.7658e-03,  2.8561e-03,  2.0147e-02,  ...,  1.2862e-02,\n",
      "          1.5066e-03,  1.3527e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0018,  0.0010, -0.0296,  ...,  0.0114,  0.0191, -0.0013],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0134,  0.0131, -0.0006,  ...,  0.0067, -0.0105, -0.0042],\n",
      "        [ 0.0096,  0.0073,  0.0032,  ..., -0.0003, -0.0038,  0.0024],\n",
      "        [ 0.0124, -0.0118, -0.0015,  ...,  0.0129, -0.0111,  0.0053],\n",
      "        ...,\n",
      "        [-0.0075,  0.0044, -0.0086,  ..., -0.0139,  0.0117,  0.0061],\n",
      "        [ 0.0136, -0.0074,  0.0023,  ..., -0.0060,  0.0006, -0.0123],\n",
      "        [ 0.0013, -0.0112,  0.0086,  ...,  0.0073,  0.0033,  0.0138]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0066,  0.0115,  0.0011,  ..., -0.0063,  0.0061,  0.0005],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0247, -0.0146, -0.0245,  ..., -0.0118,  0.0309, -0.0057],\n",
      "        [-0.0311,  0.0005,  0.0209,  ...,  0.0094, -0.0016,  0.0011],\n",
      "        [ 0.0032, -0.0147, -0.0011,  ..., -0.0021, -0.0231, -0.0157],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0171,  0.0276,  ..., -0.0214,  0.0245, -0.0068],\n",
      "        [-0.0180,  0.0131, -0.0115,  ...,  0.0276,  0.0080,  0.0089],\n",
      "        [-0.0059,  0.0274,  0.0059,  ...,  0.0233, -0.0216, -0.0071]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0179,  0.0173, -0.0202,  ...,  0.0111, -0.0304,  0.0085],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0179, -0.0124, -0.0156,  ...,  0.0030,  0.0096, -0.0186],\n",
      "        [-0.0136,  0.0219, -0.0032,  ..., -0.0041, -0.0196,  0.0073],\n",
      "        [-0.0101, -0.0265, -0.0170,  ..., -0.0229, -0.0024,  0.0230],\n",
      "        ...,\n",
      "        [-0.0021,  0.0194,  0.0191,  ...,  0.0008,  0.0034, -0.0098],\n",
      "        [-0.0035,  0.0066, -0.0275,  ..., -0.0196,  0.0261, -0.0165],\n",
      "        [ 0.0254,  0.0019, -0.0131,  ..., -0.0202,  0.0096, -0.0166]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0163,  0.0271,  0.0006,  ...,  0.0045, -0.0168, -0.0277],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0262, -0.0239,  0.0135,  ...,  0.0251,  0.0095,  0.0231],\n",
      "        [-0.0064,  0.0088,  0.0111,  ..., -0.0196,  0.0231, -0.0156],\n",
      "        [ 0.0044, -0.0241,  0.0128,  ...,  0.0147,  0.0162,  0.0147],\n",
      "        ...,\n",
      "        [-0.0200,  0.0096, -0.0304,  ...,  0.0177,  0.0310, -0.0116],\n",
      "        [-0.0095,  0.0007,  0.0176,  ..., -0.0104,  0.0164,  0.0240],\n",
      "        [-0.0003,  0.0101, -0.0173,  ..., -0.0229, -0.0020, -0.0267]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0139, -0.0275,  0.0153,  ..., -0.0124,  0.0274,  0.0203],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.6991e-03, -7.4837e-05, -6.7042e-03,  ..., -3.0755e-04,\n",
      "          1.5132e-02, -6.7047e-03],\n",
      "        [ 1.5370e-02, -8.0345e-03,  1.0374e-02,  ...,  1.8510e-04,\n",
      "          3.4273e-06,  6.1682e-03],\n",
      "        [ 5.5696e-03, -9.5080e-03,  4.6549e-03,  ..., -3.5253e-03,\n",
      "         -6.6049e-03, -4.0057e-03],\n",
      "        ...,\n",
      "        [-8.3465e-03,  2.4513e-03, -9.7315e-03,  ...,  5.5312e-03,\n",
      "          1.0465e-02, -3.5753e-03],\n",
      "        [ 8.3086e-03, -2.0118e-03, -9.2826e-03,  ..., -2.6895e-03,\n",
      "          4.1943e-03,  2.4582e-03],\n",
      "        [ 1.4562e-02, -1.0490e-02, -2.9756e-03,  ..., -1.5861e-03,\n",
      "          1.0940e-02,  6.2430e-03]], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085,  0.0131, -0.0099,  ...,  0.0049, -0.0043, -0.0140],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0008,  0.0103, -0.0114,  ...,  0.0044, -0.0251,  0.0164],\n",
      "        [ 0.0072,  0.0008,  0.0273,  ..., -0.0135, -0.0042,  0.0046],\n",
      "        [ 0.0033,  0.0276,  0.0246,  ..., -0.0247, -0.0209, -0.0175],\n",
      "        ...,\n",
      "        [ 0.0222, -0.0259, -0.0183,  ...,  0.0216,  0.0206, -0.0164],\n",
      "        [-0.0159,  0.0059, -0.0143,  ..., -0.0090,  0.0275,  0.0137],\n",
      "        [ 0.0089,  0.0091, -0.0279,  ..., -0.0042,  0.0006, -0.0175]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0140, -0.0309, -0.0290,  ...,  0.0096, -0.0043, -0.0301],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0137, -0.0173, -0.0016,  ...,  0.0172, -0.0216, -0.0147],\n",
      "        [ 0.0086,  0.0208, -0.0209,  ...,  0.0022,  0.0122, -0.0288],\n",
      "        [ 0.0095,  0.0160, -0.0257,  ..., -0.0169, -0.0245, -0.0225],\n",
      "        ...,\n",
      "        [-0.0186,  0.0220, -0.0184,  ...,  0.0034, -0.0254, -0.0195],\n",
      "        [ 0.0180,  0.0030, -0.0228,  ..., -0.0261,  0.0224, -0.0187],\n",
      "        [-0.0110, -0.0181,  0.0221,  ...,  0.0021,  0.0049, -0.0007]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0059,  0.0148, -0.0084,  ...,  0.0250,  0.0249,  0.0026],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0198,  0.0280, -0.0083,  ..., -0.0189, -0.0146, -0.0299],\n",
      "        [ 0.0154, -0.0299, -0.0018,  ..., -0.0094,  0.0146,  0.0030],\n",
      "        [ 0.0209,  0.0105, -0.0202,  ..., -0.0079, -0.0223, -0.0176],\n",
      "        ...,\n",
      "        [-0.0244,  0.0295,  0.0091,  ..., -0.0103,  0.0113,  0.0260],\n",
      "        [ 0.0060,  0.0111,  0.0112,  ..., -0.0269,  0.0201, -0.0273],\n",
      "        [-0.0186, -0.0067,  0.0046,  ..., -0.0004,  0.0075, -0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0233,  0.0211, -0.0274,  ...,  0.0044, -0.0109,  0.0309],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0091,  0.0130,  0.0090,  ..., -0.0151, -0.0026,  0.0102],\n",
      "        [ 0.0051,  0.0068,  0.0113,  ..., -0.0081,  0.0056,  0.0046],\n",
      "        [ 0.0118,  0.0008, -0.0031,  ...,  0.0151, -0.0088, -0.0033],\n",
      "        ...,\n",
      "        [-0.0104, -0.0028, -0.0062,  ...,  0.0063,  0.0123,  0.0146],\n",
      "        [-0.0154,  0.0092,  0.0049,  ...,  0.0038,  0.0009, -0.0028],\n",
      "        [-0.0090,  0.0025,  0.0049,  ..., -0.0042,  0.0055,  0.0085]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0124, -0.0014, -0.0069,  ..., -0.0017,  0.0128,  0.0127],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0092,  0.0257, -0.0026,  ..., -0.0071, -0.0048, -0.0175],\n",
      "        [ 0.0148, -0.0103, -0.0274,  ...,  0.0037, -0.0233,  0.0044],\n",
      "        [ 0.0193,  0.0249, -0.0281,  ..., -0.0262, -0.0235, -0.0145],\n",
      "        ...,\n",
      "        [-0.0083,  0.0251,  0.0269,  ..., -0.0210,  0.0101, -0.0301],\n",
      "        [ 0.0243,  0.0084,  0.0233,  ...,  0.0089,  0.0007,  0.0124],\n",
      "        [ 0.0010,  0.0105, -0.0249,  ..., -0.0014, -0.0042, -0.0256]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0185,  0.0292, -0.0019,  ...,  0.0265, -0.0098, -0.0009],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0309, -0.0121,  0.0234,  ..., -0.0083, -0.0148, -0.0103],\n",
      "        [-0.0156,  0.0129, -0.0176,  ..., -0.0200, -0.0129, -0.0257],\n",
      "        [-0.0128,  0.0236, -0.0222,  ...,  0.0074,  0.0231,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0198,  0.0143,  0.0017,  ..., -0.0190,  0.0114,  0.0304],\n",
      "        [ 0.0139, -0.0174, -0.0155,  ..., -0.0027, -0.0168, -0.0222],\n",
      "        [-0.0177,  0.0068,  0.0307,  ..., -0.0004, -0.0213,  0.0132]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0080,  0.0220,  0.0256,  ...,  0.0009, -0.0221,  0.0249],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0109,  0.0171, -0.0108,  ..., -0.0193,  0.0095, -0.0011],\n",
      "        [ 0.0049,  0.0213,  0.0252,  ...,  0.0168, -0.0006,  0.0286],\n",
      "        [ 0.0105, -0.0176, -0.0250,  ...,  0.0136, -0.0098,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0038,  0.0053,  0.0277,  ...,  0.0148,  0.0263, -0.0189],\n",
      "        [ 0.0138, -0.0100, -0.0223,  ..., -0.0275,  0.0275,  0.0007],\n",
      "        [-0.0189, -0.0312,  0.0269,  ...,  0.0293, -0.0291,  0.0082]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0093,  0.0219,  0.0210,  ..., -0.0072,  0.0157,  0.0214],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.1775e-03,  1.3074e-02,  1.0370e-03,  ..., -6.4670e-03,\n",
      "          1.3172e-02,  5.1481e-03],\n",
      "        [ 6.1968e-03, -8.4673e-03,  6.8465e-03,  ..., -1.3801e-02,\n",
      "          7.4710e-03, -8.4681e-03],\n",
      "        [ 3.6357e-03, -1.5592e-02, -5.9371e-04,  ...,  8.7213e-03,\n",
      "         -6.1290e-03, -3.3539e-03],\n",
      "        ...,\n",
      "        [-1.1666e-02,  4.5343e-03,  1.3781e-02,  ..., -1.9882e-03,\n",
      "          1.5025e-02, -1.0999e-02],\n",
      "        [-1.2493e-02,  2.2356e-03, -7.8574e-04,  ...,  6.8554e-03,\n",
      "          1.5367e-03,  8.6259e-03],\n",
      "        [ 6.6979e-03, -2.4213e-03,  1.0034e-02,  ...,  7.5914e-05,\n",
      "         -1.4591e-02, -3.4943e-04]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0040,  0.0046,  0.0131,  ..., -0.0015,  0.0073,  0.0049],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0113, -0.0207, -0.0248,  ...,  0.0124,  0.0219,  0.0251],\n",
      "        [-0.0027,  0.0006,  0.0106,  ...,  0.0194, -0.0277,  0.0250],\n",
      "        [ 0.0024, -0.0088,  0.0277,  ...,  0.0255,  0.0074, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0172, -0.0085, -0.0053,  ..., -0.0150, -0.0166, -0.0149],\n",
      "        [ 0.0055,  0.0228, -0.0183,  ...,  0.0084, -0.0200, -0.0238],\n",
      "        [ 0.0225,  0.0273, -0.0186,  ..., -0.0077,  0.0163,  0.0172]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0085, -0.0303, -0.0157,  ..., -0.0169,  0.0031,  0.0040],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0130, -0.0304, -0.0143,  ..., -0.0111, -0.0076, -0.0271],\n",
      "        [ 0.0275,  0.0035, -0.0306,  ...,  0.0175,  0.0184, -0.0284],\n",
      "        [-0.0301, -0.0240,  0.0167,  ...,  0.0098,  0.0228, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0059,  0.0192,  0.0111,  ...,  0.0152, -0.0281,  0.0195],\n",
      "        [-0.0130, -0.0181, -0.0279,  ..., -0.0145,  0.0001, -0.0115],\n",
      "        [ 0.0209, -0.0096, -0.0260,  ...,  0.0240, -0.0259,  0.0204]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0131,  0.0299,  0.0023,  ..., -0.0140,  0.0041,  0.0304],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0277, -0.0223, -0.0038,  ...,  0.0135,  0.0213,  0.0275],\n",
      "        [ 0.0211,  0.0297, -0.0053,  ...,  0.0264, -0.0298, -0.0246],\n",
      "        [-0.0030, -0.0288, -0.0143,  ..., -0.0266, -0.0096, -0.0084],\n",
      "        ...,\n",
      "        [ 0.0183,  0.0175, -0.0273,  ..., -0.0240, -0.0209,  0.0251],\n",
      "        [ 0.0223,  0.0115,  0.0264,  ..., -0.0300, -0.0306, -0.0105],\n",
      "        [-0.0100,  0.0255, -0.0092,  ..., -0.0258,  0.0004,  0.0246]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0047, -0.0259,  0.0243,  ...,  0.0193, -0.0066,  0.0190],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0050,  0.0149,  0.0020,  ...,  0.0022, -0.0089,  0.0115],\n",
      "        [-0.0083, -0.0020, -0.0081,  ...,  0.0151, -0.0109,  0.0153],\n",
      "        [ 0.0088,  0.0051, -0.0011,  ..., -0.0085, -0.0019,  0.0040],\n",
      "        ...,\n",
      "        [-0.0125, -0.0060, -0.0057,  ..., -0.0107, -0.0069, -0.0022],\n",
      "        [-0.0129,  0.0074,  0.0015,  ..., -0.0131,  0.0034, -0.0114],\n",
      "        [-0.0154,  0.0082, -0.0109,  ..., -0.0148, -0.0096,  0.0010]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0142, -0.0007, -0.0104,  ...,  0.0146, -0.0117, -0.0151],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0048,  0.0216,  0.0293,  ...,  0.0243, -0.0161, -0.0172],\n",
      "        [-0.0169,  0.0086, -0.0092,  ...,  0.0072,  0.0058, -0.0021],\n",
      "        [-0.0059,  0.0008,  0.0103,  ..., -0.0181,  0.0032,  0.0086],\n",
      "        ...,\n",
      "        [-0.0273,  0.0079,  0.0167,  ...,  0.0246,  0.0173, -0.0242],\n",
      "        [-0.0123, -0.0012,  0.0174,  ..., -0.0187,  0.0181, -0.0012],\n",
      "        [ 0.0255,  0.0167,  0.0181,  ..., -0.0142, -0.0086, -0.0242]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0009, -0.0023, -0.0084,  ...,  0.0249,  0.0097,  0.0023],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0080,  0.0088,  0.0327,  ...,  0.0224,  0.0056,  0.0166],\n",
      "        [-0.0237,  0.0027, -0.0254,  ...,  0.0059,  0.0163, -0.0426],\n",
      "        [-0.0002,  0.0190, -0.0019,  ...,  0.0218,  0.0010,  0.0078],\n",
      "        ...,\n",
      "        [-0.0326, -0.0020,  0.0144,  ...,  0.0219,  0.0310, -0.0268],\n",
      "        [-0.0108, -0.0132, -0.0392,  ...,  0.0327, -0.0046,  0.0074],\n",
      "        [ 0.0335, -0.0112, -0.0347,  ..., -0.0064, -0.0326,  0.0136]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0266,  0.0280, -0.0015,  ...,  0.0141, -0.0020, -0.0222],\n",
      "        [-0.0068,  0.0144,  0.0163,  ...,  0.0034, -0.0144,  0.0133],\n",
      "        [ 0.0172,  0.0112, -0.0167,  ..., -0.0182,  0.0161,  0.0080],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0221,  0.0217,  ...,  0.0130, -0.0142, -0.0099],\n",
      "        [-0.0057,  0.0037, -0.0139,  ...,  0.0158, -0.0137, -0.0118],\n",
      "        [ 0.0128,  0.0024, -0.0143,  ..., -0.0305,  0.0047,  0.0249]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0235, -0.0085, -0.0042,  ...,  0.0108,  0.0269, -0.0080],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0080,  0.0088,  0.0327,  ...,  0.0224,  0.0056,  0.0166],\n",
      "        [-0.0237,  0.0027, -0.0254,  ...,  0.0059,  0.0163, -0.0426],\n",
      "        [-0.0002,  0.0190, -0.0019,  ...,  0.0218,  0.0010,  0.0078],\n",
      "        ...,\n",
      "        [-0.0326, -0.0020,  0.0144,  ...,  0.0219,  0.0310, -0.0268],\n",
      "        [-0.0108, -0.0132, -0.0392,  ...,  0.0327, -0.0046,  0.0074],\n",
      "        [ 0.0335, -0.0112, -0.0347,  ..., -0.0064, -0.0326,  0.0136]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-9.1146e-03, -5.3591e-03,  8.2192e-04,  ...,  5.0118e-03,\n",
      "          3.9796e-03, -3.9810e-03],\n",
      "        [ 3.9790e-03, -2.4759e-03, -6.3266e-03,  ...,  4.8297e-04,\n",
      "          1.5337e-04,  6.2168e-03],\n",
      "        [-8.1271e-03,  1.0060e-02,  6.1895e-03,  ...,  1.5221e-03,\n",
      "          4.1717e-03, -3.1988e-04],\n",
      "        ...,\n",
      "        [ 5.3667e-03,  3.1747e-03, -1.1253e-02,  ...,  9.4612e-04,\n",
      "         -7.3206e-03,  3.8656e-03],\n",
      "        [ 4.7727e-04, -8.3654e-03,  7.7179e-03,  ...,  6.9177e-03,\n",
      "          7.8603e-03, -1.0966e-02],\n",
      "        [ 4.7190e-03,  1.3754e-02, -6.3462e-03,  ..., -7.6807e-04,\n",
      "          9.7345e-05, -1.2908e-02]], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0080,  0.0088,  0.0327,  ...,  0.0224,  0.0056,  0.0166],\n",
      "        [-0.0237,  0.0027, -0.0254,  ...,  0.0059,  0.0163, -0.0426],\n",
      "        [-0.0002,  0.0190, -0.0019,  ...,  0.0218,  0.0010,  0.0078],\n",
      "        ...,\n",
      "        [-0.0326, -0.0020,  0.0144,  ...,  0.0219,  0.0310, -0.0268],\n",
      "        [-0.0108, -0.0132, -0.0392,  ...,  0.0327, -0.0046,  0.0074],\n",
      "        [ 0.0335, -0.0112, -0.0347,  ..., -0.0064, -0.0326,  0.0136]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-9.1146e-03, -5.3591e-03,  8.2192e-04,  ...,  5.0118e-03,\n",
      "          3.9796e-03, -3.9810e-03],\n",
      "        [ 3.9790e-03, -2.4759e-03, -6.3266e-03,  ...,  4.8297e-04,\n",
      "          1.5337e-04,  6.2168e-03],\n",
      "        [-8.1271e-03,  1.0060e-02,  6.1895e-03,  ...,  1.5221e-03,\n",
      "          4.1717e-03, -3.1988e-04],\n",
      "        ...,\n",
      "        [ 5.3667e-03,  3.1747e-03, -1.1253e-02,  ...,  9.4612e-04,\n",
      "         -7.3206e-03,  3.8656e-03],\n",
      "        [ 4.7727e-04, -8.3654e-03,  7.7179e-03,  ...,  6.9177e-03,\n",
      "          7.8603e-03, -1.0966e-02],\n",
      "        [ 4.7190e-03,  1.3754e-02, -6.3462e-03,  ..., -7.6807e-04,\n",
      "          9.7345e-05, -1.2908e-02]], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0080,  0.0088,  0.0327,  ...,  0.0224,  0.0056,  0.0166],\n",
      "        [-0.0237,  0.0027, -0.0254,  ...,  0.0059,  0.0163, -0.0426],\n",
      "        [-0.0002,  0.0190, -0.0019,  ...,  0.0218,  0.0010,  0.0078],\n",
      "        ...,\n",
      "        [-0.0326, -0.0020,  0.0144,  ...,  0.0219,  0.0310, -0.0268],\n",
      "        [-0.0108, -0.0132, -0.0392,  ...,  0.0327, -0.0046,  0.0074],\n",
      "        [ 0.0335, -0.0112, -0.0347,  ..., -0.0064, -0.0326,  0.0136]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-9.1146e-03, -5.3591e-03,  8.2192e-04,  ...,  5.0118e-03,\n",
      "          3.9796e-03, -3.9810e-03],\n",
      "        [ 3.9790e-03, -2.4759e-03, -6.3266e-03,  ...,  4.8297e-04,\n",
      "          1.5337e-04,  6.2168e-03],\n",
      "        [-8.1271e-03,  1.0060e-02,  6.1895e-03,  ...,  1.5221e-03,\n",
      "          4.1717e-03, -3.1988e-04],\n",
      "        ...,\n",
      "        [ 5.3667e-03,  3.1747e-03, -1.1253e-02,  ...,  9.4612e-04,\n",
      "         -7.3206e-03,  3.8656e-03],\n",
      "        [ 4.7727e-04, -8.3654e-03,  7.7179e-03,  ...,  6.9177e-03,\n",
      "          7.8603e-03, -1.0966e-02],\n",
      "        [ 4.7190e-03,  1.3754e-02, -6.3462e-03,  ..., -7.6807e-04,\n",
      "          9.7345e-05, -1.2908e-02]], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0230,  0.0285, -0.0202,  ...,  0.0209, -0.0064,  0.0043],\n",
      "        [-0.0054,  0.0006, -0.0020,  ...,  0.0307,  0.0038, -0.0008],\n",
      "        [ 0.0238, -0.0275, -0.0057,  ...,  0.0079, -0.0296,  0.0219],\n",
      "        ...,\n",
      "        [ 0.0165, -0.0218, -0.0143,  ..., -0.0223, -0.0263, -0.0312],\n",
      "        [ 0.0236, -0.0073, -0.0117,  ...,  0.0276,  0.0290,  0.0044],\n",
      "        [ 0.0065,  0.0278, -0.0159,  ...,  0.0231, -0.0030, -0.0090]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0156, -0.0283,  0.0246,  ..., -0.0118,  0.0289, -0.0078],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0080,  0.0088,  0.0327,  ...,  0.0224,  0.0056,  0.0166],\n",
      "        [-0.0237,  0.0027, -0.0254,  ...,  0.0059,  0.0163, -0.0426],\n",
      "        [-0.0002,  0.0190, -0.0019,  ...,  0.0218,  0.0010,  0.0078],\n",
      "        ...,\n",
      "        [-0.0326, -0.0020,  0.0144,  ...,  0.0219,  0.0310, -0.0268],\n",
      "        [-0.0108, -0.0132, -0.0392,  ...,  0.0327, -0.0046,  0.0074],\n",
      "        [ 0.0335, -0.0112, -0.0347,  ..., -0.0064, -0.0326,  0.0136]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-9.1146e-03, -5.3591e-03,  8.2192e-04,  ...,  5.0118e-03,\n",
      "          3.9796e-03, -3.9810e-03],\n",
      "        [ 3.9790e-03, -2.4759e-03, -6.3266e-03,  ...,  4.8297e-04,\n",
      "          1.5337e-04,  6.2168e-03],\n",
      "        [-8.1271e-03,  1.0060e-02,  6.1895e-03,  ...,  1.5221e-03,\n",
      "          4.1717e-03, -3.1988e-04],\n",
      "        ...,\n",
      "        [ 5.3667e-03,  3.1747e-03, -1.1253e-02,  ...,  9.4612e-04,\n",
      "         -7.3206e-03,  3.8656e-03],\n",
      "        [ 4.7727e-04, -8.3654e-03,  7.7179e-03,  ...,  6.9177e-03,\n",
      "          7.8603e-03, -1.0966e-02],\n",
      "        [ 4.7190e-03,  1.3754e-02, -6.3462e-03,  ..., -7.6807e-04,\n",
      "          9.7345e-05, -1.2908e-02]], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0043, -0.0067,  0.0099,  ..., -0.0051,  0.0307,  0.0015],\n",
      "        [-0.0170, -0.0123, -0.0207,  ..., -0.0033, -0.0139,  0.0077],\n",
      "        [-0.0186, -0.0121,  0.0286,  ...,  0.0024,  0.0255,  0.0173],\n",
      "        ...,\n",
      "        [-0.0319, -0.0109,  0.0031,  ...,  0.0187,  0.0103,  0.0250],\n",
      "        [ 0.0312,  0.0188, -0.0241,  ...,  0.0229, -0.0184, -0.0279],\n",
      "        [ 0.0122, -0.0001, -0.0020,  ..., -0.0342,  0.0147,  0.0271]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0080,  0.0088,  0.0327,  ...,  0.0224,  0.0056,  0.0166],\n",
      "        [-0.0237,  0.0027, -0.0254,  ...,  0.0059,  0.0163, -0.0426],\n",
      "        [-0.0002,  0.0190, -0.0019,  ...,  0.0218,  0.0010,  0.0078],\n",
      "        ...,\n",
      "        [-0.0326, -0.0020,  0.0144,  ...,  0.0219,  0.0310, -0.0268],\n",
      "        [-0.0108, -0.0132, -0.0392,  ...,  0.0327, -0.0046,  0.0074],\n",
      "        [ 0.0335, -0.0112, -0.0347,  ..., -0.0064, -0.0326,  0.0136]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-9.1146e-03, -5.3591e-03,  8.2192e-04,  ...,  5.0118e-03,\n",
      "          3.9796e-03, -3.9810e-03],\n",
      "        [ 3.9790e-03, -2.4759e-03, -6.3266e-03,  ...,  4.8297e-04,\n",
      "          1.5337e-04,  6.2168e-03],\n",
      "        [-8.1271e-03,  1.0060e-02,  6.1895e-03,  ...,  1.5221e-03,\n",
      "          4.1717e-03, -3.1988e-04],\n",
      "        ...,\n",
      "        [ 5.3667e-03,  3.1747e-03, -1.1253e-02,  ...,  9.4612e-04,\n",
      "         -7.3206e-03,  3.8656e-03],\n",
      "        [ 4.7727e-04, -8.3654e-03,  7.7179e-03,  ...,  6.9177e-03,\n",
      "          7.8603e-03, -1.0966e-02],\n",
      "        [ 4.7190e-03,  1.3754e-02, -6.3462e-03,  ..., -7.6807e-04,\n",
      "          9.7345e-05, -1.2908e-02]], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0043, -0.0067,  0.0099,  ..., -0.0051,  0.0307,  0.0015],\n",
      "        [-0.0170, -0.0123, -0.0207,  ..., -0.0033, -0.0139,  0.0077],\n",
      "        [-0.0186, -0.0121,  0.0286,  ...,  0.0024,  0.0255,  0.0173],\n",
      "        ...,\n",
      "        [-0.0319, -0.0109,  0.0031,  ...,  0.0187,  0.0103,  0.0250],\n",
      "        [ 0.0312,  0.0188, -0.0241,  ...,  0.0229, -0.0184, -0.0279],\n",
      "        [ 0.0122, -0.0001, -0.0020,  ..., -0.0342,  0.0147,  0.0271]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0107, -0.0133, -0.0036,  ...,  0.0125, -0.0124,  0.0009],\n",
      "        [-0.0139, -0.0120, -0.0152,  ...,  0.0100,  0.0069, -0.0151],\n",
      "        [ 0.0086,  0.0074,  0.0022,  ..., -0.0055,  0.0124, -0.0066],\n",
      "        ...,\n",
      "        [ 0.0095,  0.0088,  0.0028,  ..., -0.0046, -0.0114,  0.0116],\n",
      "        [ 0.0079, -0.0021,  0.0125,  ..., -0.0145, -0.0008,  0.0142],\n",
      "        [ 0.0001,  0.0059,  0.0040,  ...,  0.0133,  0.0065, -0.0154]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([-0.0116, -0.0038,  0.0128,  ...,  0.0071, -0.0129,  0.0139],\n",
      "       requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0080,  0.0088,  0.0327,  ...,  0.0224,  0.0056,  0.0166],\n",
      "        [-0.0237,  0.0027, -0.0254,  ...,  0.0059,  0.0163, -0.0426],\n",
      "        [-0.0002,  0.0190, -0.0019,  ...,  0.0218,  0.0010,  0.0078],\n",
      "        ...,\n",
      "        [-0.0326, -0.0020,  0.0144,  ...,  0.0219,  0.0310, -0.0268],\n",
      "        [-0.0108, -0.0132, -0.0392,  ...,  0.0327, -0.0046,  0.0074],\n",
      "        [ 0.0335, -0.0112, -0.0347,  ..., -0.0064, -0.0326,  0.0136]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-9.1146e-03, -5.3591e-03,  8.2192e-04,  ...,  5.0118e-03,\n",
      "          3.9796e-03, -3.9810e-03],\n",
      "        [ 3.9790e-03, -2.4759e-03, -6.3266e-03,  ...,  4.8297e-04,\n",
      "          1.5337e-04,  6.2168e-03],\n",
      "        [-8.1271e-03,  1.0060e-02,  6.1895e-03,  ...,  1.5221e-03,\n",
      "          4.1717e-03, -3.1988e-04],\n",
      "        ...,\n",
      "        [ 5.3667e-03,  3.1747e-03, -1.1253e-02,  ...,  9.4612e-04,\n",
      "         -7.3206e-03,  3.8656e-03],\n",
      "        [ 4.7727e-04, -8.3654e-03,  7.7179e-03,  ...,  6.9177e-03,\n",
      "          7.8603e-03, -1.0966e-02],\n",
      "        [ 4.7190e-03,  1.3754e-02, -6.3462e-03,  ..., -7.6807e-04,\n",
      "          9.7345e-05, -1.2908e-02]], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0043, -0.0067,  0.0099,  ..., -0.0051,  0.0307,  0.0015],\n",
      "        [-0.0170, -0.0123, -0.0207,  ..., -0.0033, -0.0139,  0.0077],\n",
      "        [-0.0186, -0.0121,  0.0286,  ...,  0.0024,  0.0255,  0.0173],\n",
      "        ...,\n",
      "        [-0.0319, -0.0109,  0.0031,  ...,  0.0187,  0.0103,  0.0250],\n",
      "        [ 0.0312,  0.0188, -0.0241,  ...,  0.0229, -0.0184, -0.0279],\n",
      "        [ 0.0122, -0.0001, -0.0020,  ..., -0.0342,  0.0147,  0.0271]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0051,  0.0401,  0.0105,  ...,  0.0220, -0.0027, -0.0279],\n",
      "        [ 0.0166,  0.0211,  0.0130,  ..., -0.0013,  0.0259, -0.0043],\n",
      "        [-0.0143, -0.0040,  0.0118,  ..., -0.0117, -0.0138, -0.0141],\n",
      "        ...,\n",
      "        [ 0.0089, -0.0388, -0.0103,  ...,  0.0098, -0.0091, -0.0185],\n",
      "        [ 0.0139, -0.0365,  0.0020,  ..., -0.0175, -0.0058, -0.0058],\n",
      "        [-0.0193, -0.0163,  0.0111,  ..., -0.0446, -0.0075, -0.0097]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0080,  0.0088,  0.0327,  ...,  0.0224,  0.0056,  0.0166],\n",
      "        [-0.0237,  0.0027, -0.0254,  ...,  0.0059,  0.0163, -0.0426],\n",
      "        [-0.0002,  0.0190, -0.0019,  ...,  0.0218,  0.0010,  0.0078],\n",
      "        ...,\n",
      "        [-0.0326, -0.0020,  0.0144,  ...,  0.0219,  0.0310, -0.0268],\n",
      "        [-0.0108, -0.0132, -0.0392,  ...,  0.0327, -0.0046,  0.0074],\n",
      "        [ 0.0335, -0.0112, -0.0347,  ..., -0.0064, -0.0326,  0.0136]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-9.1146e-03, -5.3591e-03,  8.2192e-04,  ...,  5.0118e-03,\n",
      "          3.9796e-03, -3.9810e-03],\n",
      "        [ 3.9790e-03, -2.4759e-03, -6.3266e-03,  ...,  4.8297e-04,\n",
      "          1.5337e-04,  6.2168e-03],\n",
      "        [-8.1271e-03,  1.0060e-02,  6.1895e-03,  ...,  1.5221e-03,\n",
      "          4.1717e-03, -3.1988e-04],\n",
      "        ...,\n",
      "        [ 5.3667e-03,  3.1747e-03, -1.1253e-02,  ...,  9.4612e-04,\n",
      "         -7.3206e-03,  3.8656e-03],\n",
      "        [ 4.7727e-04, -8.3654e-03,  7.7179e-03,  ...,  6.9177e-03,\n",
      "          7.8603e-03, -1.0966e-02],\n",
      "        [ 4.7190e-03,  1.3754e-02, -6.3462e-03,  ..., -7.6807e-04,\n",
      "          9.7345e-05, -1.2908e-02]], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0043, -0.0067,  0.0099,  ..., -0.0051,  0.0307,  0.0015],\n",
      "        [-0.0170, -0.0123, -0.0207,  ..., -0.0033, -0.0139,  0.0077],\n",
      "        [-0.0186, -0.0121,  0.0286,  ...,  0.0024,  0.0255,  0.0173],\n",
      "        ...,\n",
      "        [-0.0319, -0.0109,  0.0031,  ...,  0.0187,  0.0103,  0.0250],\n",
      "        [ 0.0312,  0.0188, -0.0241,  ...,  0.0229, -0.0184, -0.0279],\n",
      "        [ 0.0122, -0.0001, -0.0020,  ..., -0.0342,  0.0147,  0.0271]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0051,  0.0401,  0.0105,  ...,  0.0220, -0.0027, -0.0279],\n",
      "        [ 0.0166,  0.0211,  0.0130,  ..., -0.0013,  0.0259, -0.0043],\n",
      "        [-0.0143, -0.0040,  0.0118,  ..., -0.0117, -0.0138, -0.0141],\n",
      "        ...,\n",
      "        [ 0.0089, -0.0388, -0.0103,  ...,  0.0098, -0.0091, -0.0185],\n",
      "        [ 0.0139, -0.0365,  0.0020,  ..., -0.0175, -0.0058, -0.0058],\n",
      "        [-0.0193, -0.0163,  0.0111,  ..., -0.0446, -0.0075, -0.0097]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0080,  0.0088,  0.0327,  ...,  0.0224,  0.0056,  0.0166],\n",
      "        [-0.0237,  0.0027, -0.0254,  ...,  0.0059,  0.0163, -0.0426],\n",
      "        [-0.0002,  0.0190, -0.0019,  ...,  0.0218,  0.0010,  0.0078],\n",
      "        ...,\n",
      "        [-0.0326, -0.0020,  0.0144,  ...,  0.0219,  0.0310, -0.0268],\n",
      "        [-0.0108, -0.0132, -0.0392,  ...,  0.0327, -0.0046,  0.0074],\n",
      "        [ 0.0335, -0.0112, -0.0347,  ..., -0.0064, -0.0326,  0.0136]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-9.1146e-03, -5.3591e-03,  8.2192e-04,  ...,  5.0118e-03,\n",
      "          3.9796e-03, -3.9810e-03],\n",
      "        [ 3.9790e-03, -2.4759e-03, -6.3266e-03,  ...,  4.8297e-04,\n",
      "          1.5337e-04,  6.2168e-03],\n",
      "        [-8.1271e-03,  1.0060e-02,  6.1895e-03,  ...,  1.5221e-03,\n",
      "          4.1717e-03, -3.1988e-04],\n",
      "        ...,\n",
      "        [ 5.3667e-03,  3.1747e-03, -1.1253e-02,  ...,  9.4612e-04,\n",
      "         -7.3206e-03,  3.8656e-03],\n",
      "        [ 4.7727e-04, -8.3654e-03,  7.7179e-03,  ...,  6.9177e-03,\n",
      "          7.8603e-03, -1.0966e-02],\n",
      "        [ 4.7190e-03,  1.3754e-02, -6.3462e-03,  ..., -7.6807e-04,\n",
      "          9.7345e-05, -1.2908e-02]], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0043, -0.0067,  0.0099,  ..., -0.0051,  0.0307,  0.0015],\n",
      "        [-0.0170, -0.0123, -0.0207,  ..., -0.0033, -0.0139,  0.0077],\n",
      "        [-0.0186, -0.0121,  0.0286,  ...,  0.0024,  0.0255,  0.0173],\n",
      "        ...,\n",
      "        [-0.0319, -0.0109,  0.0031,  ...,  0.0187,  0.0103,  0.0250],\n",
      "        [ 0.0312,  0.0188, -0.0241,  ...,  0.0229, -0.0184, -0.0279],\n",
      "        [ 0.0122, -0.0001, -0.0020,  ..., -0.0342,  0.0147,  0.0271]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0051,  0.0401,  0.0105,  ...,  0.0220, -0.0027, -0.0279],\n",
      "        [ 0.0166,  0.0211,  0.0130,  ..., -0.0013,  0.0259, -0.0043],\n",
      "        [-0.0143, -0.0040,  0.0118,  ..., -0.0117, -0.0138, -0.0141],\n",
      "        ...,\n",
      "        [ 0.0089, -0.0388, -0.0103,  ...,  0.0098, -0.0091, -0.0185],\n",
      "        [ 0.0139, -0.0365,  0.0020,  ..., -0.0175, -0.0058, -0.0058],\n",
      "        [-0.0193, -0.0163,  0.0111,  ..., -0.0446, -0.0075, -0.0097]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0080,  0.0088,  0.0327,  ...,  0.0224,  0.0056,  0.0166],\n",
      "        [-0.0237,  0.0027, -0.0254,  ...,  0.0059,  0.0163, -0.0426],\n",
      "        [-0.0002,  0.0190, -0.0019,  ...,  0.0218,  0.0010,  0.0078],\n",
      "        ...,\n",
      "        [-0.0326, -0.0020,  0.0144,  ...,  0.0219,  0.0310, -0.0268],\n",
      "        [-0.0108, -0.0132, -0.0392,  ...,  0.0327, -0.0046,  0.0074],\n",
      "        [ 0.0335, -0.0112, -0.0347,  ..., -0.0064, -0.0326,  0.0136]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-9.1146e-03, -5.3591e-03,  8.2192e-04,  ...,  5.0118e-03,\n",
      "          3.9796e-03, -3.9810e-03],\n",
      "        [ 3.9790e-03, -2.4759e-03, -6.3266e-03,  ...,  4.8297e-04,\n",
      "          1.5337e-04,  6.2168e-03],\n",
      "        [-8.1271e-03,  1.0060e-02,  6.1895e-03,  ...,  1.5221e-03,\n",
      "          4.1717e-03, -3.1988e-04],\n",
      "        ...,\n",
      "        [ 5.3667e-03,  3.1747e-03, -1.1253e-02,  ...,  9.4612e-04,\n",
      "         -7.3206e-03,  3.8656e-03],\n",
      "        [ 4.7727e-04, -8.3654e-03,  7.7179e-03,  ...,  6.9177e-03,\n",
      "          7.8603e-03, -1.0966e-02],\n",
      "        [ 4.7190e-03,  1.3754e-02, -6.3462e-03,  ..., -7.6807e-04,\n",
      "          9.7345e-05, -1.2908e-02]], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0043, -0.0067,  0.0099,  ..., -0.0051,  0.0307,  0.0015],\n",
      "        [-0.0170, -0.0123, -0.0207,  ..., -0.0033, -0.0139,  0.0077],\n",
      "        [-0.0186, -0.0121,  0.0286,  ...,  0.0024,  0.0255,  0.0173],\n",
      "        ...,\n",
      "        [-0.0319, -0.0109,  0.0031,  ...,  0.0187,  0.0103,  0.0250],\n",
      "        [ 0.0312,  0.0188, -0.0241,  ...,  0.0229, -0.0184, -0.0279],\n",
      "        [ 0.0122, -0.0001, -0.0020,  ..., -0.0342,  0.0147,  0.0271]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0051,  0.0401,  0.0105,  ...,  0.0220, -0.0027, -0.0279],\n",
      "        [ 0.0166,  0.0211,  0.0130,  ..., -0.0013,  0.0259, -0.0043],\n",
      "        [-0.0143, -0.0040,  0.0118,  ..., -0.0117, -0.0138, -0.0141],\n",
      "        ...,\n",
      "        [ 0.0089, -0.0388, -0.0103,  ...,  0.0098, -0.0091, -0.0185],\n",
      "        [ 0.0139, -0.0365,  0.0020,  ..., -0.0175, -0.0058, -0.0058],\n",
      "        [-0.0193, -0.0163,  0.0111,  ..., -0.0446, -0.0075, -0.0097]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0080,  0.0088,  0.0327,  ...,  0.0224,  0.0056,  0.0166],\n",
      "        [-0.0237,  0.0027, -0.0254,  ...,  0.0059,  0.0163, -0.0426],\n",
      "        [-0.0002,  0.0190, -0.0019,  ...,  0.0218,  0.0010,  0.0078],\n",
      "        ...,\n",
      "        [-0.0326, -0.0020,  0.0144,  ...,  0.0219,  0.0310, -0.0268],\n",
      "        [-0.0108, -0.0132, -0.0392,  ...,  0.0327, -0.0046,  0.0074],\n",
      "        [ 0.0335, -0.0112, -0.0347,  ..., -0.0064, -0.0326,  0.0136]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-9.1146e-03, -5.3591e-03,  8.2192e-04,  ...,  5.0118e-03,\n",
      "          3.9796e-03, -3.9810e-03],\n",
      "        [ 3.9790e-03, -2.4759e-03, -6.3266e-03,  ...,  4.8297e-04,\n",
      "          1.5337e-04,  6.2168e-03],\n",
      "        [-8.1271e-03,  1.0060e-02,  6.1895e-03,  ...,  1.5221e-03,\n",
      "          4.1717e-03, -3.1988e-04],\n",
      "        ...,\n",
      "        [ 5.3667e-03,  3.1747e-03, -1.1253e-02,  ...,  9.4612e-04,\n",
      "         -7.3206e-03,  3.8656e-03],\n",
      "        [ 4.7727e-04, -8.3654e-03,  7.7179e-03,  ...,  6.9177e-03,\n",
      "          7.8603e-03, -1.0966e-02],\n",
      "        [ 4.7190e-03,  1.3754e-02, -6.3462e-03,  ..., -7.6807e-04,\n",
      "          9.7345e-05, -1.2908e-02]], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0043, -0.0067,  0.0099,  ..., -0.0051,  0.0307,  0.0015],\n",
      "        [-0.0170, -0.0123, -0.0207,  ..., -0.0033, -0.0139,  0.0077],\n",
      "        [-0.0186, -0.0121,  0.0286,  ...,  0.0024,  0.0255,  0.0173],\n",
      "        ...,\n",
      "        [-0.0319, -0.0109,  0.0031,  ...,  0.0187,  0.0103,  0.0250],\n",
      "        [ 0.0312,  0.0188, -0.0241,  ...,  0.0229, -0.0184, -0.0279],\n",
      "        [ 0.0122, -0.0001, -0.0020,  ..., -0.0342,  0.0147,  0.0271]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0051,  0.0401,  0.0105,  ...,  0.0220, -0.0027, -0.0279],\n",
      "        [ 0.0166,  0.0211,  0.0130,  ..., -0.0013,  0.0259, -0.0043],\n",
      "        [-0.0143, -0.0040,  0.0118,  ..., -0.0117, -0.0138, -0.0141],\n",
      "        ...,\n",
      "        [ 0.0089, -0.0388, -0.0103,  ...,  0.0098, -0.0091, -0.0185],\n",
      "        [ 0.0139, -0.0365,  0.0020,  ..., -0.0175, -0.0058, -0.0058],\n",
      "        [-0.0193, -0.0163,  0.0111,  ..., -0.0446, -0.0075, -0.0097]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0004,  0.0248, -0.0332,  ..., -0.0224, -0.0132, -0.0120],\n",
      "        [-0.0398, -0.0089,  0.0048,  ...,  0.0381,  0.0102, -0.0156],\n",
      "        [-0.0225,  0.0102,  0.0007,  ..., -0.0233, -0.0387, -0.0022],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0015, -0.0103,  ..., -0.0127, -0.0203, -0.0024],\n",
      "        [-0.0390, -0.0056,  0.0344,  ..., -0.0169,  0.0212,  0.0377],\n",
      "        [ 0.0374, -0.0044, -0.0186,  ...,  0.0057,  0.0130, -0.0102]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0080,  0.0088,  0.0327,  ...,  0.0224,  0.0056,  0.0166],\n",
      "        [-0.0237,  0.0027, -0.0254,  ...,  0.0059,  0.0163, -0.0426],\n",
      "        [-0.0002,  0.0190, -0.0019,  ...,  0.0218,  0.0010,  0.0078],\n",
      "        ...,\n",
      "        [-0.0326, -0.0020,  0.0144,  ...,  0.0219,  0.0310, -0.0268],\n",
      "        [-0.0108, -0.0132, -0.0392,  ...,  0.0327, -0.0046,  0.0074],\n",
      "        [ 0.0335, -0.0112, -0.0347,  ..., -0.0064, -0.0326,  0.0136]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-9.1146e-03, -5.3591e-03,  8.2192e-04,  ...,  5.0118e-03,\n",
      "          3.9796e-03, -3.9810e-03],\n",
      "        [ 3.9790e-03, -2.4759e-03, -6.3266e-03,  ...,  4.8297e-04,\n",
      "          1.5337e-04,  6.2168e-03],\n",
      "        [-8.1271e-03,  1.0060e-02,  6.1895e-03,  ...,  1.5221e-03,\n",
      "          4.1717e-03, -3.1988e-04],\n",
      "        ...,\n",
      "        [ 5.3667e-03,  3.1747e-03, -1.1253e-02,  ...,  9.4612e-04,\n",
      "         -7.3206e-03,  3.8656e-03],\n",
      "        [ 4.7727e-04, -8.3654e-03,  7.7179e-03,  ...,  6.9177e-03,\n",
      "          7.8603e-03, -1.0966e-02],\n",
      "        [ 4.7190e-03,  1.3754e-02, -6.3462e-03,  ..., -7.6807e-04,\n",
      "          9.7345e-05, -1.2908e-02]], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0043, -0.0067,  0.0099,  ..., -0.0051,  0.0307,  0.0015],\n",
      "        [-0.0170, -0.0123, -0.0207,  ..., -0.0033, -0.0139,  0.0077],\n",
      "        [-0.0186, -0.0121,  0.0286,  ...,  0.0024,  0.0255,  0.0173],\n",
      "        ...,\n",
      "        [-0.0319, -0.0109,  0.0031,  ...,  0.0187,  0.0103,  0.0250],\n",
      "        [ 0.0312,  0.0188, -0.0241,  ...,  0.0229, -0.0184, -0.0279],\n",
      "        [ 0.0122, -0.0001, -0.0020,  ..., -0.0342,  0.0147,  0.0271]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0051,  0.0401,  0.0105,  ...,  0.0220, -0.0027, -0.0279],\n",
      "        [ 0.0166,  0.0211,  0.0130,  ..., -0.0013,  0.0259, -0.0043],\n",
      "        [-0.0143, -0.0040,  0.0118,  ..., -0.0117, -0.0138, -0.0141],\n",
      "        ...,\n",
      "        [ 0.0089, -0.0388, -0.0103,  ...,  0.0098, -0.0091, -0.0185],\n",
      "        [ 0.0139, -0.0365,  0.0020,  ..., -0.0175, -0.0058, -0.0058],\n",
      "        [-0.0193, -0.0163,  0.0111,  ..., -0.0446, -0.0075, -0.0097]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([ 0.0147, -0.0143,  0.0001,  ..., -0.0276, -0.0286,  0.0117],\n",
      "       requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0193,  0.0265, -0.0222,  ..., -0.0040,  0.0229,  0.0087],\n",
      "        [ 0.0151,  0.0387, -0.0025,  ..., -0.0052, -0.0255, -0.0079],\n",
      "        [ 0.0205,  0.0256, -0.0182,  ...,  0.0013, -0.0176,  0.0182],\n",
      "        ...,\n",
      "        [-0.0100,  0.0138, -0.0258,  ..., -0.0179,  0.0120, -0.0154],\n",
      "        [-0.0024, -0.0066,  0.0073,  ...,  0.0126, -0.0120, -0.0125],\n",
      "        [ 0.0371,  0.0085, -0.0057,  ...,  0.0130,  0.0105,  0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0080,  0.0088,  0.0327,  ...,  0.0224,  0.0056,  0.0166],\n",
      "        [-0.0237,  0.0027, -0.0254,  ...,  0.0059,  0.0163, -0.0426],\n",
      "        [-0.0002,  0.0190, -0.0019,  ...,  0.0218,  0.0010,  0.0078],\n",
      "        ...,\n",
      "        [-0.0326, -0.0020,  0.0144,  ...,  0.0219,  0.0310, -0.0268],\n",
      "        [-0.0108, -0.0132, -0.0392,  ...,  0.0327, -0.0046,  0.0074],\n",
      "        [ 0.0335, -0.0112, -0.0347,  ..., -0.0064, -0.0326,  0.0136]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-9.1146e-03, -5.3591e-03,  8.2192e-04,  ...,  5.0118e-03,\n",
      "          3.9796e-03, -3.9810e-03],\n",
      "        [ 3.9790e-03, -2.4759e-03, -6.3266e-03,  ...,  4.8297e-04,\n",
      "          1.5337e-04,  6.2168e-03],\n",
      "        [-8.1271e-03,  1.0060e-02,  6.1895e-03,  ...,  1.5221e-03,\n",
      "          4.1717e-03, -3.1988e-04],\n",
      "        ...,\n",
      "        [ 5.3667e-03,  3.1747e-03, -1.1253e-02,  ...,  9.4612e-04,\n",
      "         -7.3206e-03,  3.8656e-03],\n",
      "        [ 4.7727e-04, -8.3654e-03,  7.7179e-03,  ...,  6.9177e-03,\n",
      "          7.8603e-03, -1.0966e-02],\n",
      "        [ 4.7190e-03,  1.3754e-02, -6.3462e-03,  ..., -7.6807e-04,\n",
      "          9.7345e-05, -1.2908e-02]], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0043, -0.0067,  0.0099,  ..., -0.0051,  0.0307,  0.0015],\n",
      "        [-0.0170, -0.0123, -0.0207,  ..., -0.0033, -0.0139,  0.0077],\n",
      "        [-0.0186, -0.0121,  0.0286,  ...,  0.0024,  0.0255,  0.0173],\n",
      "        ...,\n",
      "        [-0.0319, -0.0109,  0.0031,  ...,  0.0187,  0.0103,  0.0250],\n",
      "        [ 0.0312,  0.0188, -0.0241,  ...,  0.0229, -0.0184, -0.0279],\n",
      "        [ 0.0122, -0.0001, -0.0020,  ..., -0.0342,  0.0147,  0.0271]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0051,  0.0401,  0.0105,  ...,  0.0220, -0.0027, -0.0279],\n",
      "        [ 0.0166,  0.0211,  0.0130,  ..., -0.0013,  0.0259, -0.0043],\n",
      "        [-0.0143, -0.0040,  0.0118,  ..., -0.0117, -0.0138, -0.0141],\n",
      "        ...,\n",
      "        [ 0.0089, -0.0388, -0.0103,  ...,  0.0098, -0.0091, -0.0185],\n",
      "        [ 0.0139, -0.0365,  0.0020,  ..., -0.0175, -0.0058, -0.0058],\n",
      "        [-0.0193, -0.0163,  0.0111,  ..., -0.0446, -0.0075, -0.0097]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0193,  0.0265, -0.0222,  ..., -0.0040,  0.0229,  0.0087],\n",
      "        [ 0.0151,  0.0387, -0.0025,  ..., -0.0052, -0.0255, -0.0079],\n",
      "        [ 0.0205,  0.0256, -0.0182,  ...,  0.0013, -0.0176,  0.0182],\n",
      "        ...,\n",
      "        [-0.0100,  0.0138, -0.0258,  ..., -0.0179,  0.0120, -0.0154],\n",
      "        [-0.0024, -0.0066,  0.0073,  ...,  0.0126, -0.0120, -0.0125],\n",
      "        [ 0.0371,  0.0085, -0.0057,  ...,  0.0130,  0.0105,  0.0021]],\n",
      "       requires_grad=True)\n",
      "pn='positional_embedding.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0061,  0.0260, -0.0136,  ..., -0.0019,  0.0002, -0.0233],\n",
      "        [ 0.0243,  0.0064,  0.0238,  ...,  0.0161,  0.0025,  0.0110],\n",
      "        [-0.0004, -0.0015, -0.0231,  ...,  0.0039, -0.0234,  0.0101],\n",
      "        ...,\n",
      "        [-0.0361, -0.0223,  0.0098,  ..., -0.0197, -0.0127,  0.0179],\n",
      "        [-0.0005,  0.0002, -0.0181,  ...,  0.0279,  0.0334, -0.0234],\n",
      "        [ 0.0103, -0.0360,  0.0228,  ..., -0.0051, -0.0013,  0.0039]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0541,  0.0054, -0.0033,  ..., -0.0176, -0.0428, -0.0029],\n",
      "        [-0.0136, -0.0287,  0.0059,  ..., -0.0426,  0.0039,  0.0069],\n",
      "        [ 0.0169,  0.0310, -0.0039,  ...,  0.0101, -0.0119, -0.0096],\n",
      "        ...,\n",
      "        [-0.0062,  0.0143,  0.0117,  ...,  0.0041,  0.0059,  0.0143],\n",
      "        [-0.0219,  0.0309, -0.0054,  ..., -0.0201, -0.0137, -0.0240],\n",
      "        [ 0.0073,  0.0004, -0.0070,  ...,  0.0238, -0.0052, -0.0003]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0002,  0.0005, -0.0076,  ..., -0.0004, -0.0028, -0.0005],\n",
      "        [ 0.0055, -0.0144, -0.0035,  ..., -0.0019,  0.0010, -0.0011],\n",
      "        [ 0.0080,  0.0012,  0.0027,  ...,  0.0024,  0.0009, -0.0010],\n",
      "        ...,\n",
      "        [ 0.0022, -0.0068,  0.0030,  ...,  0.0004, -0.0025, -0.0036],\n",
      "        [-0.0015,  0.0065,  0.0052,  ..., -0.0039, -0.0056,  0.0048],\n",
      "        [-0.0008, -0.0108, -0.0044,  ...,  0.0059, -0.0040, -0.0059]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.0.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0202, -0.0084, -0.0033,  ...,  0.0019,  0.0142,  0.0152],\n",
      "        [ 0.0237, -0.0060,  0.0131,  ..., -0.0326, -0.0057, -0.0253],\n",
      "        [ 0.0065,  0.0279, -0.0154,  ...,  0.0062, -0.0089,  0.0097],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0212, -0.0065,  ..., -0.0043,  0.0170,  0.0078],\n",
      "        [ 0.0049, -0.0204, -0.0111,  ...,  0.0135, -0.0130, -0.0247],\n",
      "        [ 0.0235,  0.0073,  0.0059,  ..., -0.0083, -0.0353,  0.0073]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0157,  0.0258, -0.0050,  ...,  0.0306,  0.0515, -0.0179],\n",
      "        [-0.0112, -0.0314,  0.0017,  ..., -0.0202, -0.0058, -0.0356],\n",
      "        [ 0.0331,  0.0247,  0.0081,  ...,  0.0025,  0.0176,  0.0237],\n",
      "        ...,\n",
      "        [-0.0023, -0.0408, -0.0240,  ..., -0.0119, -0.0024,  0.0058],\n",
      "        [-0.0369,  0.0149,  0.0259,  ...,  0.0053, -0.0142,  0.0256],\n",
      "        [-0.0131, -0.0216, -0.0177,  ..., -0.0086, -0.0102,  0.0232]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.0.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0419, -0.0095,  0.0390,  ..., -0.0194, -0.0384, -0.0105],\n",
      "        [ 0.0175,  0.0033,  0.0063,  ...,  0.0206, -0.0184,  0.0366],\n",
      "        [-0.0360, -0.0215, -0.0203,  ..., -0.0254,  0.0158, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0276,  0.0126,  ...,  0.0042,  0.0192,  0.0383],\n",
      "        [ 0.0210,  0.0172,  0.0172,  ..., -0.0091, -0.0163,  0.0067],\n",
      "        [-0.0018, -0.0397, -0.0180,  ...,  0.0186, -0.0133, -0.0335]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 1.2511e-02, -1.1637e-02,  2.1280e-03,  ..., -1.0541e-03,\n",
      "          5.3246e-03, -8.2878e-03],\n",
      "        [-6.5467e-03,  1.5163e-03,  2.0563e-03,  ...,  3.4440e-03,\n",
      "         -4.1175e-03, -6.3970e-03],\n",
      "        [-7.4169e-03,  8.7870e-03, -1.8865e-03,  ...,  6.9072e-03,\n",
      "         -7.7650e-03, -6.8741e-03],\n",
      "        ...,\n",
      "        [-1.3321e-03, -3.7439e-03, -9.9832e-03,  ...,  3.3070e-03,\n",
      "          1.7674e-03,  3.8821e-03],\n",
      "        [ 7.8873e-03, -4.9198e-03, -4.5953e-03,  ...,  3.2808e-03,\n",
      "          2.9785e-03, -6.1918e-03],\n",
      "        [-2.5302e-03, -1.6125e-03,  4.0345e-03,  ...,  2.0007e-03,\n",
      "          9.7392e-05,  2.9652e-03]], requires_grad=True)\n",
      "pn='blocks.1.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.1.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0088, -0.0022,  0.0012,  ...,  0.0090, -0.0265, -0.0008],\n",
      "        [ 0.0014,  0.0251,  0.0254,  ..., -0.0053,  0.0024,  0.0103],\n",
      "        [-0.0053, -0.0113,  0.0072,  ...,  0.0024, -0.0031, -0.0160],\n",
      "        ...,\n",
      "        [-0.0079, -0.0005, -0.0347,  ...,  0.0044,  0.0038, -0.0173],\n",
      "        [-0.0122,  0.0153,  0.0061,  ..., -0.0118,  0.0409,  0.0029],\n",
      "        [-0.0032, -0.0059,  0.0182,  ..., -0.0242,  0.0100,  0.0110]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0027,  0.0274, -0.0334,  ...,  0.0204,  0.0507,  0.0079],\n",
      "        [ 0.0125, -0.0018,  0.0075,  ..., -0.0569, -0.0102,  0.0473],\n",
      "        [-0.0477,  0.0175, -0.0464,  ...,  0.0110, -0.0014, -0.0271],\n",
      "        ...,\n",
      "        [ 0.0190,  0.0098,  0.0188,  ...,  0.0131,  0.0123, -0.0294],\n",
      "        [ 0.0097, -0.0033,  0.0169,  ..., -0.0039, -0.0252,  0.0046],\n",
      "        [-0.0053, -0.0095,  0.0008,  ...,  0.0023, -0.0006, -0.0116]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.1.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0167, -0.0024,  0.0063,  ..., -0.0330, -0.0158, -0.0529],\n",
      "        [-0.0275, -0.0373, -0.0012,  ...,  0.0074,  0.0401, -0.0113],\n",
      "        [ 0.0159, -0.0102, -0.0249,  ...,  0.0165,  0.0024,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0329, -0.0257, -0.0041,  ..., -0.0173,  0.0563,  0.0120],\n",
      "        [-0.0041, -0.0198, -0.0016,  ...,  0.0305, -0.0066, -0.0016],\n",
      "        [ 0.0300,  0.0260, -0.0001,  ..., -0.0150, -0.0105,  0.0168]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0007,  0.0013, -0.0003,  ...,  0.0026,  0.0028,  0.0096],\n",
      "        [ 0.0082,  0.0044,  0.0044,  ...,  0.0063, -0.0057, -0.0016],\n",
      "        [-0.0009,  0.0096,  0.0008,  ...,  0.0033,  0.0080, -0.0017],\n",
      "        ...,\n",
      "        [-0.0006, -0.0030, -0.0060,  ...,  0.0022,  0.0043, -0.0009],\n",
      "        [ 0.0115, -0.0028,  0.0053,  ...,  0.0040, -0.0036,  0.0040],\n",
      "        [ 0.0011,  0.0045,  0.0026,  ..., -0.0033, -0.0076, -0.0072]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.2.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.8508e-02, -3.2199e-02, -6.4161e-03,  ...,  4.3015e-02,\n",
      "          1.5807e-02,  1.1918e-02],\n",
      "        [-7.2844e-03, -1.6307e-02,  3.6397e-02,  ..., -1.4485e-02,\n",
      "         -6.4990e-03,  1.6786e-03],\n",
      "        [ 2.2966e-02, -1.1830e-02, -1.8195e-02,  ...,  1.9712e-02,\n",
      "          1.1919e-02, -1.5323e-02],\n",
      "        ...,\n",
      "        [ 4.5677e-03,  4.7603e-03,  3.1580e-03,  ..., -7.6738e-03,\n",
      "         -9.2532e-03, -4.3612e-02],\n",
      "        [ 2.8186e-02,  2.2800e-02,  1.5926e-02,  ...,  2.8264e-02,\n",
      "         -7.5728e-03, -2.0847e-02],\n",
      "        [-1.1878e-02, -7.4340e-06, -1.5504e-02,  ..., -4.2442e-03,\n",
      "         -2.9254e-02,  1.3391e-02]], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0315,  0.0044,  0.0143,  ...,  0.0159,  0.0053,  0.0085],\n",
      "        [ 0.0412, -0.0080, -0.0136,  ...,  0.0400, -0.0197, -0.0040],\n",
      "        [-0.0033, -0.0193,  0.0099,  ..., -0.0113,  0.0229, -0.0007],\n",
      "        ...,\n",
      "        [-0.0032, -0.0533,  0.0345,  ..., -0.0051,  0.0038,  0.0331],\n",
      "        [ 0.0043, -0.0059,  0.0018,  ...,  0.0357, -0.0056,  0.0012],\n",
      "        [ 0.0104, -0.0166, -0.0174,  ...,  0.0255,  0.0086, -0.0260]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.2.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0121,  0.0151, -0.0268,  ...,  0.0016,  0.0082, -0.0046],\n",
      "        [ 0.0184, -0.0352,  0.0161,  ...,  0.0300,  0.0096,  0.0021],\n",
      "        [ 0.0095,  0.0041,  0.0115,  ...,  0.0127,  0.0080,  0.0398],\n",
      "        ...,\n",
      "        [ 0.0233, -0.0174,  0.0054,  ...,  0.0217, -0.0021,  0.0145],\n",
      "        [ 0.0252,  0.0072,  0.0171,  ..., -0.0064,  0.0311,  0.0167],\n",
      "        [-0.0514,  0.0137,  0.0148,  ..., -0.0268, -0.0203,  0.0455]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0110,  0.0002,  0.0056,  ..., -0.0065, -0.0022, -0.0120],\n",
      "        [-0.0004,  0.0059, -0.0049,  ...,  0.0053,  0.0061,  0.0027],\n",
      "        [-0.0027,  0.0016,  0.0063,  ...,  0.0095, -0.0013, -0.0090],\n",
      "        ...,\n",
      "        [-0.0065,  0.0102,  0.0091,  ...,  0.0002,  0.0009,  0.0011],\n",
      "        [ 0.0024, -0.0017,  0.0043,  ..., -0.0026, -0.0018,  0.0055],\n",
      "        [-0.0036, -0.0085, -0.0005,  ...,  0.0053, -0.0005,  0.0060]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.3.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0260,  0.0251,  0.0222,  ..., -0.0017,  0.0402,  0.0092],\n",
      "        [ 0.0252,  0.0139, -0.0058,  ..., -0.0147, -0.0143,  0.0428],\n",
      "        [ 0.0273,  0.0052, -0.0347,  ..., -0.0158,  0.0345, -0.0026],\n",
      "        ...,\n",
      "        [ 0.0332, -0.0205,  0.0464,  ..., -0.0148, -0.0247, -0.0077],\n",
      "        [-0.0056,  0.0234, -0.0223,  ...,  0.0392,  0.0035,  0.0063],\n",
      "        [ 0.0010,  0.0101, -0.0119,  ...,  0.0116, -0.0163,  0.0080]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0143,  0.0118, -0.0188,  ...,  0.0199,  0.0275,  0.0128],\n",
      "        [-0.0061, -0.0102, -0.0194,  ..., -0.0081, -0.0109,  0.0129],\n",
      "        [-0.0118, -0.0359,  0.0365,  ..., -0.0291, -0.0286, -0.0323],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0309,  0.0063,  ...,  0.0184, -0.0333,  0.0395],\n",
      "        [-0.0034,  0.0371,  0.0128,  ..., -0.0413,  0.0344,  0.0003],\n",
      "        [ 0.0057,  0.0215, -0.0139,  ...,  0.0068, -0.0178,  0.0415]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.3.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0086, -0.0002,  0.0214,  ..., -0.0150,  0.0249, -0.0058],\n",
      "        [ 0.0356, -0.0162,  0.0072,  ...,  0.0093, -0.0281,  0.0019],\n",
      "        [-0.0158, -0.0269, -0.0181,  ...,  0.0157,  0.0289,  0.0322],\n",
      "        ...,\n",
      "        [ 0.0192, -0.0166, -0.0358,  ..., -0.0004, -0.0045, -0.0096],\n",
      "        [ 0.0084,  0.0074,  0.0262,  ...,  0.0255, -0.0065,  0.0087],\n",
      "        [ 0.0001,  0.0159,  0.0359,  ...,  0.0111,  0.0216,  0.0134]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 9.3534e-03,  1.6036e-03,  1.9225e-03,  ..., -2.9982e-03,\n",
      "         -1.2394e-03, -9.0959e-04],\n",
      "        [ 1.8732e-03, -5.4704e-03,  2.9138e-03,  ...,  3.4810e-03,\n",
      "          2.5772e-04, -4.5322e-04],\n",
      "        [ 1.0561e-02, -5.0532e-03,  8.4883e-03,  ...,  1.2336e-03,\n",
      "         -6.3964e-05, -4.4667e-03],\n",
      "        ...,\n",
      "        [-6.3676e-03, -8.6552e-03, -4.7680e-03,  ..., -5.4497e-03,\n",
      "         -5.4245e-03,  4.2294e-04],\n",
      "        [-2.0827e-03, -5.0095e-03, -5.8146e-03,  ...,  2.1033e-04,\n",
      "          1.2911e-03, -2.7351e-03],\n",
      "        [ 6.8758e-03, -5.8043e-03, -7.4452e-03,  ..., -6.2936e-04,\n",
      "          4.5790e-03, -4.5867e-03]], requires_grad=True)\n",
      "pn='blocks.4.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.4.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0041, -0.0034,  0.0038,  ...,  0.0132, -0.0154, -0.0008],\n",
      "        [-0.0099, -0.0175, -0.0129,  ..., -0.0222,  0.0072, -0.0521],\n",
      "        [ 0.0063, -0.0115, -0.0183,  ..., -0.0028, -0.0023,  0.0283],\n",
      "        ...,\n",
      "        [ 0.0062,  0.0150, -0.0311,  ..., -0.0135, -0.0115, -0.0235],\n",
      "        [ 0.0115, -0.0111, -0.0005,  ...,  0.0021,  0.0090, -0.0071],\n",
      "        [-0.0155,  0.0375, -0.0122,  ...,  0.0147,  0.0057,  0.0103]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0053,  0.0136,  0.0063,  ..., -0.0109,  0.0021,  0.0273],\n",
      "        [-0.0238, -0.0157,  0.0040,  ..., -0.0117, -0.0034,  0.0003],\n",
      "        [-0.0145,  0.0155, -0.0050,  ...,  0.0019, -0.0397, -0.0157],\n",
      "        ...,\n",
      "        [-0.0113,  0.0383,  0.0440,  ..., -0.0147,  0.0018,  0.0089],\n",
      "        [-0.0189, -0.0015, -0.0006,  ..., -0.0308, -0.0231,  0.0051],\n",
      "        [ 0.0123,  0.0090, -0.0212,  ...,  0.0134,  0.0046, -0.0217]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.4.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0165,  0.0219, -0.0277,  ...,  0.0296, -0.0049,  0.0052],\n",
      "        [ 0.0004,  0.0184,  0.0275,  ..., -0.0017, -0.0002,  0.0084],\n",
      "        [ 0.0002,  0.0072,  0.0198,  ..., -0.0084, -0.0021, -0.0437],\n",
      "        ...,\n",
      "        [ 0.0337, -0.0049, -0.0029,  ...,  0.0317,  0.0237, -0.0197],\n",
      "        [ 0.0036, -0.0053,  0.0171,  ...,  0.0174, -0.0120, -0.0353],\n",
      "        [ 0.0396,  0.0534, -0.0333,  ...,  0.0327,  0.0284,  0.0027]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-7.9690e-04, -4.5230e-03,  9.1575e-03,  ..., -1.3219e-02,\n",
      "          2.2004e-03,  1.0053e-02],\n",
      "        [-7.6753e-03, -5.7477e-03, -8.8249e-05,  ..., -3.1117e-03,\n",
      "         -5.2670e-03, -7.6885e-04],\n",
      "        [-3.5545e-03,  3.1242e-03,  2.7546e-03,  ..., -5.3231e-03,\n",
      "          2.9316e-03, -1.7218e-03],\n",
      "        ...,\n",
      "        [-5.9778e-03,  8.9874e-03, -2.3786e-03,  ...,  4.6292e-03,\n",
      "         -2.5793e-03,  9.7774e-03],\n",
      "        [ 4.2508e-03, -1.7653e-03, -6.4811e-03,  ..., -5.5265e-03,\n",
      "         -5.9204e-03,  1.4878e-04],\n",
      "        [-4.2247e-03,  1.1493e-04,  2.1131e-03,  ..., -8.4514e-03,\n",
      "          5.0743e-03, -6.7873e-04]], requires_grad=True)\n",
      "pn='blocks.5.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.5.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0071, -0.0148,  0.0193,  ...,  0.0218,  0.0174, -0.0080],\n",
      "        [-0.0144,  0.0038, -0.0045,  ...,  0.0053,  0.0065,  0.0161],\n",
      "        [-0.0213,  0.0010,  0.0097,  ...,  0.0054, -0.0008,  0.0169],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0108,  0.0671,  ...,  0.0524, -0.0141, -0.0005],\n",
      "        [ 0.0018, -0.0100, -0.0063,  ...,  0.0241,  0.0398,  0.0132],\n",
      "        [-0.0085, -0.0195,  0.0234,  ...,  0.0254,  0.0004,  0.0173]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-1.7936e-02,  7.6337e-03,  1.4484e-02,  ..., -1.4495e-02,\n",
      "         -2.3678e-02,  8.4516e-03],\n",
      "        [ 3.2612e-02, -1.2387e-02, -1.2852e-02,  ..., -5.2235e-03,\n",
      "          2.0796e-02, -3.0841e-02],\n",
      "        [ 3.5021e-02,  2.1653e-02, -3.0354e-02,  ...,  3.3459e-03,\n",
      "          2.7634e-03,  2.1488e-02],\n",
      "        ...,\n",
      "        [-6.1420e-02,  9.9815e-03,  7.2145e-05,  ...,  7.9099e-03,\n",
      "          2.8717e-02,  3.0625e-02],\n",
      "        [ 1.3727e-02,  2.9201e-02,  3.7328e-02,  ...,  3.5978e-03,\n",
      "         -1.2443e-02,  1.1534e-02],\n",
      "        [-2.9577e-02,  1.4774e-02,  1.5772e-02,  ...,  2.9776e-03,\n",
      "          3.3943e-03, -9.8140e-03]], requires_grad=True)\n",
      "pn='blocks.5.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0174,  0.0186, -0.0071,  ...,  0.0159,  0.0066, -0.0011],\n",
      "        [ 0.0060, -0.0064, -0.0027,  ..., -0.0032, -0.0313, -0.0238],\n",
      "        [-0.0158, -0.0066, -0.0173,  ...,  0.0212, -0.0198, -0.0031],\n",
      "        ...,\n",
      "        [-0.0087, -0.0120,  0.0174,  ..., -0.0085,  0.0024, -0.0225],\n",
      "        [-0.0028, -0.0248,  0.0163,  ...,  0.0150,  0.0253, -0.0509],\n",
      "        [-0.0294, -0.0104, -0.0020,  ...,  0.0162, -0.0206, -0.0238]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0097,  0.0029,  0.0018,  ..., -0.0025, -0.0002,  0.0013],\n",
      "        [ 0.0008, -0.0018, -0.0023,  ...,  0.0006,  0.0058, -0.0018],\n",
      "        [-0.0006, -0.0063,  0.0047,  ...,  0.0030, -0.0011,  0.0045],\n",
      "        ...,\n",
      "        [-0.0083,  0.0089, -0.0067,  ..., -0.0083,  0.0009,  0.0021],\n",
      "        [ 0.0059, -0.0042, -0.0012,  ..., -0.0027, -0.0037, -0.0023],\n",
      "        [-0.0051, -0.0034,  0.0025,  ..., -0.0022,  0.0052,  0.0005]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.6.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-5.1688e-03,  9.4763e-03,  1.7943e-03,  ..., -1.8100e-02,\n",
      "         -1.8261e-03,  1.4798e-02],\n",
      "        [-1.3315e-02,  8.7913e-05, -1.1972e-02,  ..., -1.9373e-02,\n",
      "         -1.9039e-02, -2.5262e-03],\n",
      "        [-1.7672e-02, -4.2859e-04,  1.8964e-02,  ...,  9.7117e-03,\n",
      "          2.6597e-02,  8.4652e-03],\n",
      "        ...,\n",
      "        [ 1.4128e-02, -9.7909e-04,  1.3717e-02,  ...,  1.5775e-02,\n",
      "          1.1269e-02,  1.2198e-03],\n",
      "        [-1.2076e-02, -4.0027e-02, -2.0346e-02,  ...,  8.5833e-03,\n",
      "          4.7634e-04, -2.5765e-02],\n",
      "        [-2.5358e-02, -2.8742e-02, -4.1538e-02,  ...,  3.0906e-03,\n",
      "         -1.2334e-02,  1.0119e-02]], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0112,  0.0150,  0.0036,  ...,  0.0404,  0.0223,  0.0342],\n",
      "        [ 0.0160, -0.0108,  0.0175,  ...,  0.0063,  0.0303,  0.0335],\n",
      "        [-0.0254, -0.0010, -0.0077,  ..., -0.0133,  0.0096, -0.0089],\n",
      "        ...,\n",
      "        [ 0.0191, -0.0514, -0.0012,  ..., -0.0173,  0.0348, -0.0290],\n",
      "        [ 0.0301, -0.0126, -0.0364,  ..., -0.0131,  0.0087,  0.0116],\n",
      "        [ 0.0003, -0.0162,  0.0165,  ..., -0.0153,  0.0058, -0.0241]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.6.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm1.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0080,  0.0088,  0.0327,  ...,  0.0224,  0.0056,  0.0166],\n",
      "        [-0.0237,  0.0027, -0.0254,  ...,  0.0059,  0.0163, -0.0426],\n",
      "        [-0.0002,  0.0190, -0.0019,  ...,  0.0218,  0.0010,  0.0078],\n",
      "        ...,\n",
      "        [-0.0326, -0.0020,  0.0144,  ...,  0.0219,  0.0310, -0.0268],\n",
      "        [-0.0108, -0.0132, -0.0392,  ...,  0.0327, -0.0046,  0.0074],\n",
      "        [ 0.0335, -0.0112, -0.0347,  ..., -0.0064, -0.0326,  0.0136]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_attn.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-9.1146e-03, -5.3591e-03,  8.2192e-04,  ...,  5.0118e-03,\n",
      "          3.9796e-03, -3.9810e-03],\n",
      "        [ 3.9790e-03, -2.4759e-03, -6.3266e-03,  ...,  4.8297e-04,\n",
      "          1.5337e-04,  6.2168e-03],\n",
      "        [-8.1271e-03,  1.0060e-02,  6.1895e-03,  ...,  1.5221e-03,\n",
      "          4.1717e-03, -3.1988e-04],\n",
      "        ...,\n",
      "        [ 5.3667e-03,  3.1747e-03, -1.1253e-02,  ...,  9.4612e-04,\n",
      "         -7.3206e-03,  3.8656e-03],\n",
      "        [ 4.7727e-04, -8.3654e-03,  7.7179e-03,  ...,  6.9177e-03,\n",
      "          7.8603e-03, -1.0966e-02],\n",
      "        [ 4.7190e-03,  1.3754e-02, -6.3462e-03,  ..., -7.6807e-04,\n",
      "          9.7345e-05, -1.2908e-02]], requires_grad=True)\n",
      "pn='blocks.7.MultiheadAttention.c_proj.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='blocks.7.LayerNorm2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[-0.0043, -0.0067,  0.0099,  ..., -0.0051,  0.0307,  0.0015],\n",
      "        [-0.0170, -0.0123, -0.0207,  ..., -0.0033, -0.0139,  0.0077],\n",
      "        [-0.0186, -0.0121,  0.0286,  ...,  0.0024,  0.0255,  0.0173],\n",
      "        ...,\n",
      "        [-0.0319, -0.0109,  0.0031,  ...,  0.0187,  0.0103,  0.0250],\n",
      "        [ 0.0312,  0.0188, -0.0241,  ...,  0.0229, -0.0184, -0.0279],\n",
      "        [ 0.0122, -0.0001, -0.0020,  ..., -0.0342,  0.0147,  0.0271]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.0.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.weight'\n",
      "p=Parameter containing:\n",
      "tensor([[ 0.0051,  0.0401,  0.0105,  ...,  0.0220, -0.0027, -0.0279],\n",
      "        [ 0.0166,  0.0211,  0.0130,  ..., -0.0013,  0.0259, -0.0043],\n",
      "        [-0.0143, -0.0040,  0.0118,  ..., -0.0117, -0.0138, -0.0141],\n",
      "        ...,\n",
      "        [ 0.0089, -0.0388, -0.0103,  ...,  0.0098, -0.0091, -0.0185],\n",
      "        [ 0.0139, -0.0365,  0.0020,  ..., -0.0175, -0.0058, -0.0058],\n",
      "        [-0.0193, -0.0163,  0.0111,  ..., -0.0446, -0.0075, -0.0097]],\n",
      "       requires_grad=True)\n",
      "pn='blocks.7.MLP.MLP.2.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='LayerNorm3.weight'\n",
      "p=Parameter containing:\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)\n",
      "pn='LayerNorm3.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
      "pn='lm_linear.bias'\n",
      "p=Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50304 \n",
    "block_size = 2048\n",
    "batch_size = 4 \n",
    "device = \"mps\"\n",
    "\n",
    "model = Model1(block_size=block_size, vocab_size=vocab_size, embed_dim=1024, num_heads=16, num_blocks=8, dropout=0.2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0233, -0.0098,  0.0083,  ...,  0.0012, -0.0085,  0.0162],\n",
      "        [-0.0065,  0.0057, -0.0044,  ...,  0.0196, -0.0193,  0.0081],\n",
      "        [-0.0028,  0.0045,  0.0129,  ...,  0.0197, -0.0049,  0.0122],\n",
      "        ...,\n",
      "        [-0.0098, -0.0319, -0.0006,  ...,  0.0243,  0.0197,  0.0014],\n",
      "        [-0.0174,  0.0069, -0.0192,  ...,  0.0074, -0.0357,  0.0383],\n",
      "        [ 0.0093, -0.0023,  0.0202,  ..., -0.0142,  0.0134,  0.0128]],\n",
      "       device='mps:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model1(\n",
       "  (embedding): Embedding(50304, 1024)\n",
       "  (positional_embedding): Embedding(2048, 1024)\n",
       "  (blocks): ModuleList(\n",
       "    (0-7): 8 x Block(\n",
       "      (LayerNorm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (MultiheadAttention): CausalSelfAttention(\n",
       "        (c_attn): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (LayerNorm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (MLP): MLP(\n",
       "        (MLP): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (LayerNorm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_linear): Linear(in_features=1024, out_features=50304, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "vocab_size = 50304 \n",
    "block_size = 2048\n",
    "batch_size = 4 \n",
    "device = \"mps\"\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt2\")\n",
    "eot = enc._special_tokens['<|endoftext|>'] \n",
    "model = Model1(block_size=block_size, vocab_size=vocab_size, embed_dim=1024, num_heads=16, num_blocks=8, dropout=0.2).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 0: Hello, I'm a language model, JD\n",
      "sample 1: Hello, I'm a language model, Pebble\n",
      "sample 2: Hello, I'm a language model, podcast\n",
      "sample 3: Hello, I'm a language model,DE\n",
      "sample 0: Hello, I'm a language model, JDbed\n",
      "sample 1: Hello, I'm a language model, Pebble theoret\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian\n",
      "sample 3: Hello, I'm a language model,DE Sessions\n",
      "sample 0: Hello, I'm a language model, JDbedicians\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needs\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgar\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger Relax\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger Relaxriots\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMV\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger Relaxriotsjar\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreed\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles Explan\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation Wi\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404 Package\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles Explaneros\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain shiny\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation Wi vas\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404 Package\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles ExplanerosWa\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain shiny Dragons\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation Wi vas Rich\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404 Package embarrass\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles ExplanerosWa him\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain shiny Dragons narrowly\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation Wi vas Richales\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404 Package embarrassGES\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles ExplanerosWa him Alpine\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain shiny Dragons narrowly Particularly\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation Wi vas Richales Ascend\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404 Package embarrassGESMass\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles ExplanerosWa him Alpine Documents\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain shiny Dragons narrowly Particularly Particularly\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation Wi vas Richales Ascend\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404 Package embarrassGESMass inscribed\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles ExplanerosWa him Alpine Documents predis\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain shiny Dragons narrowly Particularly Particularlyocytes\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation Wi vas Richales Ascend Prelude\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404 Package embarrassGESMass inscribedLyn\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles ExplanerosWa him Alpine Documents predis Tem\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain shiny Dragons narrowly Particularly Particularlyocytesregulated\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation Wi vas Richales Ascend Prelude wrought\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404 Package embarrassGESMass inscribedLyn Qi\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles ExplanerosWa him Alpine Documents predis Temotyp\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain shiny Dragons narrowly Particularly Particularlyocytesregulated Prelude\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation Wi vas Richales Ascend Prelude wroughtKids\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404 Package embarrassGESMass inscribedLyn Qi Berserker\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles ExplanerosWa him Alpine Documents predis Temotyp Rich\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain shiny Dragons narrowly Particularly Particularlyocytesregulated PreludeDs\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation Wi vas Richales Ascend Prelude wroughtKids Pier\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404 Package embarrassGESMass inscribedLyn Qi Berserker bu\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles ExplanerosWa him Alpine Documents predis Temotyp Rich mineral\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain shiny Dragons narrowly Particularly Particularlyocytesregulated PreludeDs Prelude\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation Wi vas Richales Ascend Prelude wroughtKids PierLP\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404 Package embarrassGESMass inscribedLyn Qi Berserker bu necklace\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles ExplanerosWa him Alpine Documents predis Temotyp Rich mineral butterfly\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain shiny Dragons narrowly Particularly Particularlyocytesregulated PreludeDs Prelude opt\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation Wi vas Richales Ascend Prelude wroughtKids PierLP XI\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404 Package embarrassGESMass inscribedLyn Qi Berserker bu necklace batches\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles ExplanerosWa him Alpine Documents predis Temotyp Rich mineral butterflyOriginally\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain shiny Dragons narrowly Particularly Particularlyocytesregulated PreludeDs Prelude opt compound\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation Wi vas Richales Ascend Prelude wroughtKids PierLP XI Better\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404 Package embarrassGESMass inscribedLyn Qi Berserker bu necklace batches Frem\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles ExplanerosWa him Alpine Documents predis Temotyp Rich mineral butterflyOriginallypent\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain shiny Dragons narrowly Particularly Particularlyocytesregulated PreludeDs Prelude opt compound indigenous\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation Wi vas Richales Ascend Prelude wroughtKids PierLP XI Better Defensive\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404 Package embarrassGESMass inscribedLyn Qi Berserker bu necklace batches Frem longing\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles ExplanerosWa him Alpine Documents predis Temotyp Rich mineral butterflyOriginallypent Bad\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain shiny Dragons narrowly Particularly Particularlyocytesregulated PreludeDs Prelude opt compound indigenous exterior\n",
      "sample 0: Hello, I'm a language model, JDbediciansRoger RelaxriotsjarANCE initiation Wi vas Richales Ascend Prelude wroughtKids PierLP XI Better Defensive contacts\n",
      "sample 1: Hello, I'm a language model, Pebble theoret Sprite vulgarAK dungeons disagreedusalem 404 Package embarrassGESMass inscribedLyn Qi Berserker bu necklace batches Frem longing Vale\n",
      "sample 2: Hello, I'm a language model, podcast Egyptian needsrm owning450 nobles ExplanerosWa him Alpine Documents predis Temotyp Rich mineral butterflyOriginallypent Bad competing\n",
      "sample 3: Hello, I'm a language model,DE Sessions labor naming premiered DMVizens almost Chain shiny Dragons narrowly Particularly Particularlyocytesregulated PreludeDs Prelude opt compound indigenous exterior Sept\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "num_return_sequences = 4\n",
    "max_length = 32\n",
    "tokens = enc.encode(\"Hello, I'm a language model,\")\n",
    "tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)\n",
    "xgen = tokens.to(device)\n",
    "while xgen.size(1) < max_length:\n",
    "    with torch.no_grad():\n",
    "        logits = model(xgen) # (B, T, vocab_size)\n",
    "        logits = logits[:, -1, :] # (B, vocab_size)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "                # select a token from the top-k probabilities\n",
    "                # note: multinomial does not demand the input to sum to 1\n",
    "        ix = torch.multinomial(topk_probs, 1) # (B, 1)\n",
    "                # gather the corresponding indices\n",
    "        xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "                # append to the sequence\n",
    "        xgen = torch.cat((xgen, xcol), dim=1)\n",
    "    \n",
    "    for i in range(num_return_sequences):\n",
    "            tokens = xgen[i, :max_length].tolist()\n",
    "            decoded = enc.decode(tokens)\n",
    "            print(f\"sample {i}: {decoded}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3e-5\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./optimizer1_weights.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/learning-pytroch-compoutervision/lib/python3.11/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/learning-pytroch-compoutervision/lib/python3.11/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/learning-pytroch-compoutervision/lib/python3.11/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/learning-pytroch-compoutervision/lib/python3.11/site-packages/torch/serialization.py:1116\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1112\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39mUntypedStorage)\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1116\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1117\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1121\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/learning-pytroch-compoutervision/lib/python3.11/site-packages/torch/serialization.py:217\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 217\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(storage, location)\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/learning-pytroch-compoutervision/lib/python3.11/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m         device \u001b[38;5;241m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/learning-pytroch-compoutervision/lib/python3.11/site-packages/torch/serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    163\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    168\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    170\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    171\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
    "optimizer.load_state_dict(torch.load(\"./optimizer1_weights.pth\", weights_only=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RSMNorm(nn.Module):\n",
    "    def __init__(self, input_shape, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.g = nn.Parameter(torch.ones(input_shape))\n",
    "        self.b = nn.Parameter(torch.ones(input_shape))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        rms = torch.sqrt(torch.mean(x ** 2, dim=-1, keepdim=True) + self.eps)\n",
    "        output = x / rms \n",
    "        output = (output * self.g) + self.b\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = nn.LayerNorm(normalized_shape=100)\n",
    "norm(torch.randn(100)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = RSMNorm(100)\n",
    "norm(torch.randn(100)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fineweb_gpt2_transformer_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
